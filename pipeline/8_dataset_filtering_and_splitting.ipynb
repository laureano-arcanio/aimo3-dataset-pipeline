{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Split: Train / Test (Normalized Format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from typing import Optional\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "# Source JSONL files to load and concatenate\n",
    "DATASET_PATH = \"/home/larcanio/AIMO3_v2/data/datasets/Dataset_Full/bucketed/dataset_full_metadata.jsonl\"\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = \"/home/larcanio/AIMO3_v2/data/datasets/splits/gemma_balanced\"\n",
    "\n",
    "# Filtering Options\n",
    "\n",
    "# Only include records where outcome.status == \"success\"\n",
    "REQUIRE_CORRECT = True\n",
    "\n",
    "# Effective difficulty levels to include (None = all levels)\n",
    "# Derived from computation_buckets: min level where passes >= 1\n",
    "# Available levels: 0, 1, 2, 3, 4, 5, 6, 7 (None = problem unsolved by any bucket)\n",
    "EFFECTIVE_DIFFICULTY: Optional[list[int]] = [1, 2,3 ]\n",
    "\n",
    "# Code scores to include (None = all scores)\n",
    "CODE_SCORES: Optional[list[int]] = None\n",
    "\n",
    "# Solution token range: (min, max) estimated tokens for problem.original_solution\n",
    "# Estimated as len(text) // 4. Set to None to disable.\n",
    "SOLUTION_TOKEN_RANGE: Optional[tuple[int, int]] = None #(0,512) #None  # e.g. (0, 500)\n",
    "\n",
    "# Math Structure Filters\n",
    "# Filters based on math_structure.from_text and math_structure.from_solution\n",
    "# Set to None to disable a filter.\n",
    "\n",
    "# Max number of constraints in math_structure.from_text.constraints (None = no limit)\n",
    "MAX_CONSTRAINT_COUNT: Optional[int] = 1\n",
    "\n",
    "# Max number of objects in math_structure.from_text.objects (None = no limit)\n",
    "MAX_OBJECT_COUNT: Optional[int] = 1\n",
    "\n",
    "# Allowed reasoning depths from math_structure.from_solution.reasoning_depth (None = all)\n",
    "REASONING_DEPTH: Optional[list[str]] = [\"shallow\", \"medium\"] # [\"deep\", \"shallow\", \"medium\"]\n",
    "\n",
    "# Domain Distribution\n",
    "# Specify percentage (1-100) of final dataset per domain.\n",
    "# Percentages should sum to 100. Set to None to use all domains equally.\n",
    "# Domains not listed will be excluded.\n",
    "\n",
    "DOMAIN_DISTRIBUTION: Optional[dict[str, int]] = {\n",
    "    \"algebra\": 65,\n",
    "    \"combinatorics\": 20,\n",
    "    \"geometry\": 5,\n",
    "    \"number_theory\": 10,\n",
    "    \n",
    "}\n",
    "\n",
    "# Dataset Source Distribution\n",
    "# Specify percentage (1-100) of final dataset per source dataset (record[\"dataset\"]).\n",
    "# Percentages should sum to <= 100. Set to None to keep all records (no resampling).\n",
    "# Applied after domain distribution.\n",
    "# Available datasets: gsm8k, numina1.5, mvidia_reasoning_steps,\n",
    "#   numina1.5:aops, numina1.5:cn_contest, numina1.5:metamath,\n",
    "#   numina1.5:inequalities, numina1.5:number_theory\n",
    "\n",
    "# Example:\n",
    "# DATASET_DISTRIBUTION: Optional[dict[str, int]] = {\n",
    "#     \"gsm8k\": 55,\n",
    "#     \"numina1.5\": 15,\n",
    "#     \"mvidia_reasoning_steps\": 20,\n",
    "# }\n",
    "DATASET_DISTRIBUTION = None\n",
    "\n",
    "# Target Dataset Size\n",
    "TARGET_TOTAL_RECORDS: Optional[int] = 15000\n",
    "\n",
    "# Train/Test Split\n",
    "TRAIN_RATIO = 0.9\n",
    "TEST_RATIO = 0.1\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded records from bucketed/dataset_full_metadata.jsonl\n",
      "\n",
      "Total records loaded: 71,832\n"
     ]
    }
   ],
   "source": [
    "# ── Load  ─────────────────────────────────────────────────────\n",
    "\n",
    "records = []\n",
    "\n",
    "with open(DATASET_PATH) as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            records.append(json.loads(line))\n",
    "\n",
    "\n",
    "print(f\"Loaded records from {Path(DATASET_PATH).parent.name}/{Path(DATASET_PATH).name}\")\n",
    "\n",
    "print(f\"\\nTotal records loaded: {len(records):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filtering: 71,832 -> 7,382  (dropped 64,450)\n",
      "\n",
      "Active filters:\n",
      "  - Require correct: True\n",
      "  - Effective difficulty: [1, 2, 3]\n",
      "  - Code scores: all\n",
      "  - Solution tokens: all\n",
      "  - Max constraint count: 1\n",
      "  - Max object count: 1\n",
      "  - Reasoning depth: ['shallow', 'medium']\n"
     ]
    }
   ],
   "source": [
    "# ── Apply filters ──────────────────────────────────────────────────────────\n",
    "\n",
    "# Convert lists to sets for O(1) lookup\n",
    "_effective_difficulty_set = set(EFFECTIVE_DIFFICULTY) if EFFECTIVE_DIFFICULTY else None\n",
    "_code_scores_set = set(CODE_SCORES) if CODE_SCORES else None\n",
    "_reasoning_depth_set = set(REASONING_DEPTH) if REASONING_DEPTH else None\n",
    "\n",
    "\n",
    "def get_effective_difficulty(r: dict) -> int | None:\n",
    "    \"\"\"Compute effective difficulty: minimum bucket level where passes >= 1.\"\"\"\n",
    "    buckets = r.get(\"computation_buckets\", [])\n",
    "    passing = [b[\"level\"] for b in buckets if b.get(\"passes\", 0) >= 1]\n",
    "    return min(passing) if passing else None\n",
    "\n",
    "\n",
    "def _estimate_tokens(text: str) -> int:\n",
    "    \"\"\"Estimate token count from text (avg ~4 chars per token).\"\"\"\n",
    "    return len(text) // 4\n",
    "\n",
    "\n",
    "def passes_filters(r: dict) -> bool:\n",
    "    \"\"\"Check if a record passes all configured filters.\"\"\"\n",
    "    audit = r.get(\"audit\", {})\n",
    "    outcome = r.get(\"outcome\", {})\n",
    "    \n",
    "    # Correctness filter (outcome.status == \"success\")\n",
    "    if REQUIRE_CORRECT and outcome.get(\"status\") != \"success\":\n",
    "        return False\n",
    "    \n",
    "    # Effective difficulty filter (from computation_buckets)\n",
    "    if _effective_difficulty_set is not None:\n",
    "        eff_diff = get_effective_difficulty(r)\n",
    "        if eff_diff is None or eff_diff not in _effective_difficulty_set:\n",
    "            return False\n",
    "    \n",
    "    # Code score filter (audit.code_score)\n",
    "    if _code_scores_set is not None:\n",
    "        code_score = audit.get(\"code_score\")\n",
    "        if code_score is not None and code_score not in _code_scores_set:\n",
    "            return False\n",
    "    \n",
    "    # Solution token range filter (problem.original_solution)\n",
    "    if SOLUTION_TOKEN_RANGE is not None:\n",
    "        solution = r.get(\"problem\", {}).get(\"original_solution\") or \"\"\n",
    "        sol_tokens = _estimate_tokens(solution)\n",
    "        lo, hi = SOLUTION_TOKEN_RANGE\n",
    "        if sol_tokens < lo or sol_tokens > hi:\n",
    "            return False\n",
    "    \n",
    "    # ── Math structure filters ─────────────────────────────────────────\n",
    "    ms = r.get(\"math_structure\") or {}\n",
    "    from_text = ms.get(\"from_text\") or {}\n",
    "    from_solution = ms.get(\"from_solution\") or {}\n",
    "    \n",
    "    # Constraint count filter (math_structure.from_text.constraints)\n",
    "    if MAX_CONSTRAINT_COUNT is not None:\n",
    "        constraints = from_text.get(\"constraints\") or []\n",
    "        if len(constraints) > MAX_CONSTRAINT_COUNT:\n",
    "            return False\n",
    "    \n",
    "    # Object count filter (math_structure.from_text.objects)\n",
    "    if MAX_OBJECT_COUNT is not None:\n",
    "        objects = from_text.get(\"objects\") or []\n",
    "        if len(objects) > MAX_OBJECT_COUNT:\n",
    "            return False\n",
    "    \n",
    "    # Reasoning depth filter (math_structure.from_solution.reasoning_depth)\n",
    "    if _reasoning_depth_set is not None:\n",
    "        reasoning_depth = from_solution.get(\"reasoning_depth\")\n",
    "        if reasoning_depth is not None and reasoning_depth not in _reasoning_depth_set:\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "before = len(records)\n",
    "records = [r for r in records if passes_filters(r)]\n",
    "after = len(records)\n",
    "\n",
    "# Annotate records with effective_difficulty for downstream use\n",
    "for r in records:\n",
    "    r[\"_effective_difficulty\"] = get_effective_difficulty(r)\n",
    "\n",
    "print(f\"After filtering: {before:,} -> {after:,}  (dropped {before - after:,})\")\n",
    "print(\"\\nActive filters:\")\n",
    "print(f\"  - Require correct: {REQUIRE_CORRECT}\")\n",
    "print(f\"  - Effective difficulty: {EFFECTIVE_DIFFICULTY or 'all'}\")\n",
    "print(f\"  - Code scores: {CODE_SCORES or 'all'}\")\n",
    "if SOLUTION_TOKEN_RANGE:\n",
    "    print(f\"  - Solution tokens: [{SOLUTION_TOKEN_RANGE[0]}, {SOLUTION_TOKEN_RANGE[1]}] (estimated, ~4 chars/token)\")\n",
    "else:\n",
    "    print(\"  - Solution tokens: all\")\n",
    "print(f\"  - Max constraint count: {MAX_CONSTRAINT_COUNT or 'all'}\")\n",
    "print(f\"  - Max object count: {MAX_OBJECT_COUNT or 'all'}\")\n",
    "print(f\"  - Reasoning depth: {REASONING_DEPTH or 'all'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available records by domain (after filtering):\n",
      "  algebra: 3,909\n",
      "  number_theory: 1,824\n",
      "  combinatorics: 1,154\n",
      "  geometry: 407\n",
      "  mixed: 62\n",
      "  unknown: 21\n",
      "  None: 5\n"
     ]
    }
   ],
   "source": [
    "# ── Show available data by domain ──────────────────────────────────────────\n",
    "\n",
    "import random\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "def get_domain(r: dict) -> str:\n",
    "    \"\"\"Null-safe domain extraction from math_structure.from_text.domain.\"\"\"\n",
    "    ms = r.get(\"math_structure\") or {}\n",
    "    ft = ms.get(\"from_text\") or {}\n",
    "    return ft.get(\"domain\", \"unknown\")\n",
    "\n",
    "\n",
    "# Group records by domain\n",
    "by_domain: dict[str, list] = {}\n",
    "for r in records:\n",
    "    domain = get_domain(r)\n",
    "    by_domain.setdefault(domain, []).append(r)\n",
    "\n",
    "print(\"Available records by domain (after filtering):\")\n",
    "for domain, recs in sorted(by_domain.items(), key=lambda x: -len(x[1])):\n",
    "    print(f\"  {domain}: {len(recs):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain distribution analysis:\n",
      "  User target:            15,000\n",
      "  Listed domains total:   7,294\n",
      "  Max proportional target: 5,770 (bottleneck: combinatorics with 1,154 records @ 20%)\n",
      "  Effective target:       5,770\n",
      "\n",
      "  NOTE: Capping at 5,770 to maintain exact distribution proportions.\n",
      "\n",
      "Allocation (target: 5,770):\n",
      "  algebra: 3,750 / 3,909 available [65.0% actual vs 65% desired]\n",
      "  combinatorics: 1,154 / 1,154 available (ALL) [20.0% actual vs 20% desired]\n",
      "  geometry: 288 / 407 available [5.0% actual vs 5% desired]\n",
      "  number_theory: 577 / 1,824 available [10.0% actual vs 10% desired]\n",
      "\n",
      "  Total allocated: 5,770 / 5,770\n",
      "\n",
      "  Unused records: 1,524 from listed domains, 88 from unlisted domains (1,612 total)\n",
      "\n",
      "Final dataset size: 5,770\n"
     ]
    }
   ],
   "source": [
    "# ── Apply domain distribution ──────────────────────────────────────────────\n",
    "\n",
    "selected_records = []\n",
    "\n",
    "if DOMAIN_DISTRIBUTION is not None:\n",
    "    # Validate percentages\n",
    "    total_pct = sum(DOMAIN_DISTRIBUTION.values())\n",
    "    if total_pct > 100:\n",
    "        raise ValueError(f\"Domain percentages sum to {total_pct}%, must be <= 100%\")\n",
    "    \n",
    "    target_size = TARGET_TOTAL_RECORDS or len(records)\n",
    "    \n",
    "    max_proportional_targets = []\n",
    "    for domain, pct in DOMAIN_DISTRIBUTION.items():\n",
    "        available = len(by_domain.get(domain, []))\n",
    "        if pct > 0:\n",
    "            max_for_domain = int(available / (pct / 100))\n",
    "            max_proportional_targets.append((domain, max_for_domain, available, pct))\n",
    "    \n",
    "    max_proportional_targets.sort(key=lambda x: x[1])\n",
    "    bottleneck_domain, max_achievable, bn_available, bn_pct = max_proportional_targets[0]\n",
    "\n",
    "    listed_available = sum(len(by_domain.get(d, [])) for d in DOMAIN_DISTRIBUTION)\n",
    "    effective_target = min(target_size, listed_available, max_achievable)\n",
    "    \n",
    "    print(\"Domain distribution analysis:\")\n",
    "    print(f\"  User target:            {target_size:,}\")\n",
    "    print(f\"  Listed domains total:   {listed_available:,}\")\n",
    "    print(f\"  Max proportional target: {max_achievable:,} (bottleneck: {bottleneck_domain} \"\n",
    "          f\"with {bn_available:,} records @ {bn_pct}%)\")\n",
    "    print(f\"  Effective target:       {effective_target:,}\\n\")\n",
    "    \n",
    "    if effective_target < target_size:\n",
    "        print(f\"  NOTE: Capping at {effective_target:,} to maintain exact distribution proportions.\\n\")\n",
    "    \n",
    "    domain_allocated = {}\n",
    "    total_allocated = 0\n",
    "    \n",
    "    print(f\"Allocation (target: {effective_target:,}):\")\n",
    "    for domain, pct in DOMAIN_DISTRIBUTION.items():\n",
    "        available = by_domain.get(domain, [])\n",
    "        desired = int(effective_target * pct / 100)\n",
    "        allocated = min(desired, len(available))\n",
    "        domain_allocated[domain] = allocated\n",
    "        total_allocated += allocated\n",
    "        \n",
    "        actual_pct = (allocated / effective_target * 100) if effective_target > 0 else 0\n",
    "        tag = \" (ALL)\" if allocated == len(available) else \"\"\n",
    "        print(f\"  {domain}: {allocated:,} / {len(available):,} available{tag} \"\n",
    "              f\"[{actual_pct:.1f}% actual vs {pct}% desired]\")\n",
    "    \n",
    "    remainder = effective_target - total_allocated\n",
    "    if remainder > 0:\n",
    "        for domain, pct in sorted(DOMAIN_DISTRIBUTION.items(), key=lambda x: -x[1]):\n",
    "            if remainder == 0:\n",
    "                break\n",
    "            available = len(by_domain.get(domain, []))\n",
    "            capacity = available - domain_allocated[domain]\n",
    "            add = min(remainder, capacity)\n",
    "            if add > 0:\n",
    "                domain_allocated[domain] += add\n",
    "                total_allocated += add\n",
    "                remainder -= add\n",
    "    \n",
    "    print(f\"\\n  Total allocated: {total_allocated:,} / {effective_target:,}\")\n",
    "    \n",
    "    for domain, count in domain_allocated.items():\n",
    "        if count > 0:\n",
    "            available = by_domain.get(domain, [])\n",
    "            if count >= len(available):\n",
    "                selected_records.extend(available)\n",
    "            else:\n",
    "                selected_records.extend(random.sample(available, count))\n",
    "    \n",
    "    unused_listed = listed_available - total_allocated\n",
    "    unused_other = sum(len(v) for d, v in by_domain.items() if d not in DOMAIN_DISTRIBUTION)\n",
    "    if unused_listed > 0 or unused_other > 0:\n",
    "        print(f\"\\n  Unused records: {unused_listed:,} from listed domains, \"\n",
    "              f\"{unused_other:,} from unlisted domains ({unused_listed + unused_other:,} total)\")\n",
    "else:\n",
    "    selected_records = records\n",
    "    print(\"No domain distribution specified - using all filtered records\")\n",
    "\n",
    "random.shuffle(selected_records)\n",
    "records = selected_records\n",
    "\n",
    "print(f\"\\nFinal dataset size: {len(records):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available records by dataset source (after previous filters):\n",
      "  gsm8k: 3,498\n",
      "  numina1.5:mixed: 1,125\n",
      "  open_math_reasoning: 935\n",
      "  numina1.5:metamath: 125\n",
      "  numina1.5:cn_contest: 47\n",
      "  numina1.5:aops: 34\n",
      "  numina1.5:inequalities: 4\n",
      "  numina1.5:number_theory: 2\n",
      "\n",
      "No dataset distribution specified - keeping all records\n",
      "Current dataset size: 5,770\n"
     ]
    }
   ],
   "source": [
    "by_dataset: dict[str, list] = {}\n",
    "for r in records:\n",
    "    ds = r.get(\"dataset\", \"unknown\")\n",
    "    by_dataset.setdefault(ds, []).append(r)\n",
    "\n",
    "print(\"Available records by dataset source (after previous filters):\")\n",
    "for ds, recs in sorted(by_dataset.items(), key=lambda x: -len(x[1])):\n",
    "    print(f\"  {ds}: {len(recs):,}\")\n",
    "\n",
    "if DATASET_DISTRIBUTION is not None:\n",
    "    total_pct = sum(DATASET_DISTRIBUTION.values())\n",
    "    if total_pct > 100:\n",
    "        raise ValueError(f\"Dataset percentages sum to {total_pct}%, must be <= 100%\")\n",
    "\n",
    "    pool_size = len(records)\n",
    "\n",
    "    max_proportional_targets = []\n",
    "    for ds_name, pct in DATASET_DISTRIBUTION.items():\n",
    "        available = len(by_dataset.get(ds_name, []))\n",
    "        if pct > 0:\n",
    "            max_for_ds = int(available / (pct / 100))\n",
    "            max_proportional_targets.append((ds_name, max_for_ds, available, pct))\n",
    "\n",
    "    max_proportional_targets.sort(key=lambda x: x[1])\n",
    "    bn_ds, max_achievable, bn_available, bn_pct = max_proportional_targets[0]\n",
    "\n",
    "    listed_available = sum(len(by_dataset.get(d, [])) for d in DATASET_DISTRIBUTION)\n",
    "    effective_target = min(pool_size, listed_available, max_achievable)\n",
    "\n",
    "    print(\"\\nDataset distribution analysis:\")\n",
    "    print(f\"  Pool size:              {pool_size:,}\")\n",
    "    print(f\"  Listed datasets total:  {listed_available:,}\")\n",
    "    print(f\"  Max proportional target: {max_achievable:,} (bottleneck: {bn_ds} \"\n",
    "          f\"with {bn_available:,} records @ {bn_pct}%)\")\n",
    "    print(f\"  Effective target:       {effective_target:,}\")\n",
    "\n",
    "    if effective_target < pool_size:\n",
    "        print(f\"\\n  NOTE: Capping at {effective_target:,} to maintain exact dataset proportions.\")\n",
    "\n",
    "    ds_allocated = {}\n",
    "    total_allocated = 0\n",
    "\n",
    "    print(f\"\\nAllocation (target: {effective_target:,}):\")\n",
    "    for ds_name, pct in DATASET_DISTRIBUTION.items():\n",
    "        available = by_dataset.get(ds_name, [])\n",
    "        desired = int(effective_target * pct / 100)\n",
    "        allocated = min(desired, len(available))\n",
    "        ds_allocated[ds_name] = allocated\n",
    "        total_allocated += allocated\n",
    "\n",
    "        actual_pct = (allocated / effective_target * 100) if effective_target > 0 else 0\n",
    "        tag = \" (ALL)\" if allocated == len(available) else \"\"\n",
    "        print(f\"  {ds_name}: {allocated:,} / {len(available):,} available{tag} \"\n",
    "              f\"[{actual_pct:.1f}% actual vs {pct}% desired]\")\n",
    "\n",
    "    remainder = effective_target - total_allocated\n",
    "    if remainder > 0:\n",
    "        for ds_name, pct in sorted(DATASET_DISTRIBUTION.items(), key=lambda x: -x[1]):\n",
    "            if remainder == 0:\n",
    "                break\n",
    "            available = len(by_dataset.get(ds_name, []))\n",
    "            capacity = available - ds_allocated[ds_name]\n",
    "            add = min(remainder, capacity)\n",
    "            if add > 0:\n",
    "                ds_allocated[ds_name] += add\n",
    "                total_allocated += add\n",
    "                remainder -= add\n",
    "\n",
    "    print(f\"\\n  Total allocated: {total_allocated:,} / {effective_target:,}\")\n",
    "\n",
    "    ds_selected = []\n",
    "    for ds_name, count in ds_allocated.items():\n",
    "        if count > 0:\n",
    "            available = by_dataset.get(ds_name, [])\n",
    "            if count >= len(available):\n",
    "                ds_selected.extend(available)\n",
    "            else:\n",
    "                ds_selected.extend(random.sample(available, count))\n",
    "\n",
    "    unused_listed = listed_available - total_allocated\n",
    "    unused_other = sum(len(v) for d, v in by_dataset.items() if d not in DATASET_DISTRIBUTION)\n",
    "    if unused_listed > 0 or unused_other > 0:\n",
    "        print(f\"\\n  Unused records: {unused_listed:,} from listed datasets, \"\n",
    "              f\"{unused_other:,} from unlisted datasets ({unused_listed + unused_other:,} total)\")\n",
    "\n",
    "    random.shuffle(ds_selected)\n",
    "    records = ds_selected\n",
    "    print(f\"\\nDataset size after dataset distribution: {len(records):,}\")\n",
    "else:\n",
    "    print(\"\\nNo dataset distribution specified - keeping all records\")\n",
    "    print(f\"Current dataset size: {len(records):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset validation:\n",
      "  Target: 15000\n",
      "  Actual: 5,770\n",
      "  ⚠️  Shortfall: 9,230 records (38.5% of target)\n"
     ]
    }
   ],
   "source": [
    "print(\"Final dataset validation:\")\n",
    "print(f\"  Target: {TARGET_TOTAL_RECORDS or 'unlimited'}\")\n",
    "print(f\"  Actual: {len(records):,}\")\n",
    "\n",
    "if TARGET_TOTAL_RECORDS is not None:\n",
    "    if len(records) == TARGET_TOTAL_RECORDS:\n",
    "        print(\"  ✓ Target achieved\")\n",
    "    elif len(records) < TARGET_TOTAL_RECORDS:\n",
    "        shortfall = TARGET_TOTAL_RECORDS - len(records)\n",
    "        pct = (len(records) / TARGET_TOTAL_RECORDS) * 100\n",
    "        print(f\"  ⚠️  Shortfall: {shortfall:,} records ({pct:.1f}% of target)\")\n",
    "    else:\n",
    "        # This shouldn't happen with the new algorithm, but safety check\n",
    "        print(f\"  ⚠️  WARNING: Exceeded target by {len(records) - TARGET_TOTAL_RECORDS:,} records\")\n",
    "        print(\"     Downsampling to target size...\")\n",
    "        records = random.sample(records, TARGET_TOTAL_RECORDS)\n",
    "        print(f\"  ✓ Downsampled to {len(records):,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratification groups:\n",
      "  algebra_D1: 570\n",
      "  algebra_D2: 2,127\n",
      "  algebra_D3: 1,054\n",
      "  combinatorics_D1: 107\n",
      "  combinatorics_D2: 619\n",
      "  combinatorics_D3: 428\n",
      "  geometry_D1: 33\n",
      "  geometry_D2: 128\n",
      "  geometry_D3: 127\n",
      "  number_theory_D1: 92\n",
      "  number_theory_D2: 292\n",
      "  number_theory_D3: 193\n",
      "\n",
      "Train: 4,904\n",
      "Test:  866\n"
     ]
    }
   ],
   "source": [
    "# Build stratification keys based on domain + effective_difficulty\n",
    "strat_keys = []\n",
    "for r in records:\n",
    "    domain = get_domain(r)\n",
    "    eff_diff = r.get(\"_effective_difficulty\", \"NA\")\n",
    "    strat_keys.append(f\"{domain}_D{eff_diff}\")\n",
    "\n",
    "print(\"Stratification groups:\")\n",
    "for k, v in sorted(Counter(strat_keys).items()):\n",
    "    print(f\"  {k}: {v:,}\")\n",
    "\n",
    "strat_counts = Counter(strat_keys)\n",
    "safe_keys = [\n",
    "    k if strat_counts[k] >= 2 else \"_rare_\"\n",
    "    for k in strat_keys\n",
    "]\n",
    "\n",
    "rare_count = sum(1 for k in safe_keys if k == \"_rare_\")\n",
    "if rare_count:\n",
    "    print(f\"\\nMerged {rare_count} record(s) from singleton strata into '_rare_' group\")\n",
    "\n",
    "indices = list(range(len(records)))\n",
    "\n",
    "train_idx, test_idx = train_test_split(\n",
    "    indices,\n",
    "    test_size=TEST_RATIO,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=safe_keys,\n",
    ")\n",
    "\n",
    "train_records = [records[i] for i in train_idx]\n",
    "test_records = [records[i] for i in test_idx]\n",
    "\n",
    "print(f\"\\nTrain: {len(train_records):,}\")\n",
    "print(f\"Test:  {len(test_records):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>total</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>train_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>algebra_D1</td>\n",
       "      <td>570</td>\n",
       "      <td>484</td>\n",
       "      <td>86</td>\n",
       "      <td>84.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>algebra_D2</td>\n",
       "      <td>2127</td>\n",
       "      <td>1808</td>\n",
       "      <td>319</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>algebra_D3</td>\n",
       "      <td>1054</td>\n",
       "      <td>896</td>\n",
       "      <td>158</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>combinatorics_D1</td>\n",
       "      <td>107</td>\n",
       "      <td>91</td>\n",
       "      <td>16</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>combinatorics_D2</td>\n",
       "      <td>619</td>\n",
       "      <td>526</td>\n",
       "      <td>93</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>combinatorics_D3</td>\n",
       "      <td>428</td>\n",
       "      <td>364</td>\n",
       "      <td>64</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>geometry_D1</td>\n",
       "      <td>33</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>84.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>geometry_D2</td>\n",
       "      <td>128</td>\n",
       "      <td>109</td>\n",
       "      <td>19</td>\n",
       "      <td>85.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>geometry_D3</td>\n",
       "      <td>127</td>\n",
       "      <td>108</td>\n",
       "      <td>19</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>number_theory_D1</td>\n",
       "      <td>92</td>\n",
       "      <td>78</td>\n",
       "      <td>14</td>\n",
       "      <td>84.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>number_theory_D2</td>\n",
       "      <td>292</td>\n",
       "      <td>248</td>\n",
       "      <td>44</td>\n",
       "      <td>84.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>number_theory_D3</td>\n",
       "      <td>193</td>\n",
       "      <td>164</td>\n",
       "      <td>29</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               group  total  train  test  train_%\n",
       "0         algebra_D1    570    484    86     84.9\n",
       "1         algebra_D2   2127   1808   319     85.0\n",
       "2         algebra_D3   1054    896   158     85.0\n",
       "3   combinatorics_D1    107     91    16     85.0\n",
       "4   combinatorics_D2    619    526    93     85.0\n",
       "5   combinatorics_D3    428    364    64     85.0\n",
       "6        geometry_D1     33     28     5     84.8\n",
       "7        geometry_D2    128    109    19     85.2\n",
       "8        geometry_D3    127    108    19     85.0\n",
       "9   number_theory_D1     92     78    14     84.8\n",
       "10  number_theory_D2    292    248    44     84.9\n",
       "11  number_theory_D3    193    164    29     85.0"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_strat = Counter(strat_keys[i] for i in train_idx)\n",
    "test_strat = Counter(strat_keys[i] for i in test_idx)\n",
    "all_groups = sorted(set(strat_keys))\n",
    "\n",
    "rows = []\n",
    "for g in all_groups:\n",
    "    total = train_strat.get(g, 0) + test_strat.get(g, 0)\n",
    "    rows.append({\n",
    "        \"group\": g,\n",
    "        \"total\": total,\n",
    "        \"train\": train_strat.get(g, 0),\n",
    "        \"test\": test_strat.get(g, 0),\n",
    "        \"train_%\": round(train_strat.get(g, 0) / total * 100, 1) if total else 0,\n",
    "    })\n",
    "\n",
    "pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples per dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>total</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>pct_of_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gsm8k</td>\n",
       "      <td>3498</td>\n",
       "      <td>2986</td>\n",
       "      <td>512</td>\n",
       "      <td>60.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>numina1.5:mixed</td>\n",
       "      <td>1125</td>\n",
       "      <td>947</td>\n",
       "      <td>178</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>open_math_reasoning</td>\n",
       "      <td>935</td>\n",
       "      <td>789</td>\n",
       "      <td>146</td>\n",
       "      <td>16.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>numina1.5:metamath</td>\n",
       "      <td>125</td>\n",
       "      <td>109</td>\n",
       "      <td>16</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>numina1.5:cn_contest</td>\n",
       "      <td>47</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>numina1.5:aops</td>\n",
       "      <td>34</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>numina1.5:inequalities</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>numina1.5:number_theory</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   dataset  total  train  test  pct_of_total\n",
       "0                    gsm8k   3498   2986   512          60.6\n",
       "1          numina1.5:mixed   1125    947   178          19.5\n",
       "2      open_math_reasoning    935    789   146          16.2\n",
       "3       numina1.5:metamath    125    109    16           2.2\n",
       "4     numina1.5:cn_contest     47     39     8           0.8\n",
       "5           numina1.5:aops     34     29     5           0.6\n",
       "6   numina1.5:inequalities      4      3     1           0.1\n",
       "7  numina1.5:number_theory      2      2     0           0.0"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = Counter(r.get(\"dataset\", \"unknown\") for r in train_records)\n",
    "test_ds = Counter(r.get(\"dataset\", \"unknown\") for r in test_records)\n",
    "all_datasets = sorted(set(train_ds) | set(test_ds))\n",
    "\n",
    "ds_rows = []\n",
    "for ds in all_datasets:\n",
    "    total = train_ds.get(ds, 0) + test_ds.get(ds, 0)\n",
    "    ds_rows.append({\n",
    "        \"dataset\": ds,\n",
    "        \"total\": total,\n",
    "        \"train\": train_ds.get(ds, 0),\n",
    "        \"test\": test_ds.get(ds, 0),\n",
    "        \"pct_of_total\": round(total / len(records) * 100, 1),\n",
    "    })\n",
    "\n",
    "ds_rows.sort(key=lambda x: -x[\"total\"])\n",
    "\n",
    "print(\"Samples per dataset:\")\n",
    "pd.DataFrame(ds_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 4,904 train records -> /home/larcanio/AIMO3_v2/data/datasets/splits/gemma_balanced/train.jsonl\n",
      "Saved 866 test records  -> /home/larcanio/AIMO3_v2/data/datasets/splits/gemma_balanced/test.jsonl\n",
      "\n",
      "============================================================\n",
      "DATASET SUMMARY\n",
      "============================================================\n",
      "Sources: 87 datasets\n",
      "Filters: correct=True\n",
      "         effective_difficulty=[1, 2, 3]\n",
      "         code_scores=all\n",
      "         solution_tokens=all\n",
      "         max_constraint_count=1\n",
      "         max_object_count=1\n",
      "         reasoning_depth=['shallow', 'medium']\n",
      "Domains: algebra:65%, combinatorics:20%, geometry:5%, number_theory:10%\n",
      "Datasets: all (no distribution)\n",
      "Target:  15000\n",
      "Split:   85% train / 15% test\n",
      "Output:  /home/larcanio/AIMO3_v2/data/datasets/splits/gemma_balanced\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "train_path = os.path.join(OUTPUT_DIR, \"train.jsonl\")\n",
    "test_path = os.path.join(OUTPUT_DIR, \"test.jsonl\")\n",
    "\n",
    "with open(train_path, \"w\") as f:\n",
    "    for r in train_records:\n",
    "        f.write(json.dumps(r) + \"\\n\")\n",
    "\n",
    "with open(test_path, \"w\") as f:\n",
    "    for r in test_records:\n",
    "        f.write(json.dumps(r) + \"\\n\")\n",
    "\n",
    "print(f\"Saved {len(train_records):,} train records -> {train_path}\")\n",
    "print(f\"Saved {len(test_records):,} test records  -> {test_path}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Sources: {len(DATASET_PATH)} datasets\")\n",
    "print(f\"Filters: correct={REQUIRE_CORRECT}\")\n",
    "print(f\"         effective_difficulty={EFFECTIVE_DIFFICULTY or 'all'}\")\n",
    "print(f\"         code_scores={CODE_SCORES or 'all'}\")\n",
    "if SOLUTION_TOKEN_RANGE:\n",
    "    print(f\"         solution_tokens=[{SOLUTION_TOKEN_RANGE[0]}-{SOLUTION_TOKEN_RANGE[1]}]\")\n",
    "else:\n",
    "    print(\"         solution_tokens=all\")\n",
    "print(f\"         max_constraint_count={MAX_CONSTRAINT_COUNT or 'all'}\")\n",
    "print(f\"         max_object_count={MAX_OBJECT_COUNT or 'all'}\")\n",
    "print(f\"         reasoning_depth={REASONING_DEPTH or 'all'}\")\n",
    "if DOMAIN_DISTRIBUTION:\n",
    "    print(f\"Domains: {', '.join(f'{d}:{p}%' for d, p in DOMAIN_DISTRIBUTION.items())}\")\n",
    "else:\n",
    "    print(\"Domains: all (no distribution)\")\n",
    "if DATASET_DISTRIBUTION:\n",
    "    print(f\"Datasets: {', '.join(f'{d}:{p}%' for d, p in DATASET_DISTRIBUTION.items())}\")\n",
    "else:\n",
    "    print(\"Datasets: all (no distribution)\")\n",
    "print(f\"Target:  {TARGET_TOTAL_RECORDS or 'unlimited'}\")\n",
    "print(f\"Split:   {TRAIN_RATIO*100:.0f}% train / {TEST_RATIO*100:.0f}% test\")\n",
    "print(f\"Output:  {OUTPUT_DIR}\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
