{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "OUTPUT_BASE_DIR = Path('/home/larcanio/AIMO3_v2/data/datasets/Dataset_Full/')\n",
    "RUN_DIR = OUTPUT_BASE_DIR / 'bucketed'\n",
    "INPUT_FILENAME = 'dataset_full_metadata.jsonl'\n",
    "OUTPUT_FILENAME = 'dataset_normalized.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the JSONL file\n",
    "if RUN_DIR is None:\n",
    "    # Find the most recent run directory\n",
    "    run_dirs = sorted([d for d in OUTPUT_BASE_DIR.iterdir() if d.is_dir()], reverse=True)\n",
    "    if not run_dirs:\n",
    "        raise FileNotFoundError(f\"No run directories found in {OUTPUT_BASE_DIR}\")\n",
    "    RUN_DIR = run_dirs[0]\n",
    "    print(f\"Using most recent run directory: {RUN_DIR.name}\")\n",
    "else:\n",
    "    print(f\"Using specified run directory: {RUN_DIR.name}\")\n",
    "\n",
    "jsonl_file = RUN_DIR / INPUT_FILENAME\n",
    "\n",
    "if not jsonl_file.exists():\n",
    "    raise FileNotFoundError(f\"JSONL file not found: {jsonl_file}\")\n",
    "\n",
    "print(f\"Reading from: {jsonl_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and parse JSONL file\n",
    "datapoints = []\n",
    "with open(jsonl_file, 'r', encoding='utf-8') as f:\n",
    "    for line_num, line in enumerate(f, 1):\n",
    "        if line.strip():  # Skip empty lines\n",
    "            try:\n",
    "                datapoint = json.loads(line)\n",
    "                datapoints.append(datapoint)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing line {line_num}: {e}\")\n",
    "                print(f\"Line content: {line[:200]}...\")\n",
    "\n",
    "NUM_ITEMS_TO_DISPLAY = 10\n",
    "print(f\"\\nTotal datapoints loaded: {len(datapoints)}\")\n",
    "print(f\"Displaying first {min(NUM_ITEMS_TO_DISPLAY, len(datapoints))} items:\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# Normalized output schema  (field -> source path)\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "#\n",
    "# Identity\n",
    "#   id                          -> uuid4()\n",
    "#   source_license              -> record.license\n",
    "#   timestamp                   -> record.timestamp\n",
    "#\n",
    "# Problem definition\n",
    "#   domain                      -> math_structure.from_text.domain\n",
    "#   level                       -> lowest computation_buckets[].level where passes >= 1\n",
    "#   text                        -> problem.text\n",
    "#   solution                    -> problem.original_solution\n",
    "#   expected_answer             -> problem.expected_answer\n",
    "#\n",
    "# Math structure (from text)\n",
    "#   objects                     -> math_structure.from_text.objects\n",
    "#   constraints                 -> math_structure.from_text.constraints\n",
    "#\n",
    "# Math structure (from solution)\n",
    "#   reasoning_depth             -> math_structure.from_solution.reasoning_depth\n",
    "#   technique_transitions       -> math_structure.from_solution.technique_transitions\n",
    "#   reasoning_scope             -> math_structure.from_solution.reasoning_scope\n",
    "#   intermediate_reuse          -> math_structure.from_solution.intermediate_reuse\n",
    "#\n",
    "# Code artifact & telemetry\n",
    "#   code                        -> first attempt with exec.status == \"success\"\n",
    "#   code_attempts               -> outcome.execution_attempts\n",
    "#   code_runtime_ms             -> successful attempt exec.duration (seconds -> ms)\n",
    "#   code_generated_tokens       -> tokenizer(code)\n",
    "#   code_predicted_correct_answer -> successful attempt result.correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _successful_attempt(record):\n",
    "    \"\"\"First attempt with exec.status == 'success'.\"\"\"\n",
    "    for a in record.get(\"attempts\", []):\n",
    "        if (a.get(\"exec\") or {}).get(\"status\") == \"success\":\n",
    "            return a\n",
    "    return None\n",
    "\n",
    "\n",
    "def _lowest_passing_level(record):\n",
    "    \"\"\"Lowest computation_buckets level where passes >= 1, or None.\"\"\"\n",
    "    buckets = record.get(\"computation_buckets\") or []\n",
    "    passing = [b[\"level\"] for b in buckets if b.get(\"passes\", 0) >= 1]\n",
    "    return min(passing) if passing else None\n",
    "\n",
    "\n",
    "def record_to_flat(record, tokenizer_fn=None):\n",
    "    \"\"\"\n",
    "    Convert one source record to the normalized flat format.\n",
    "    Returns None if there is no successful attempt.\n",
    "    \"\"\"\n",
    "    attempt = _successful_attempt(record)\n",
    "    if attempt is None:\n",
    "        return None\n",
    "\n",
    "    problem = record.get(\"problem\") or {}\n",
    "    outcome = record.get(\"outcome\") or {}\n",
    "    math_struct = record.get(\"math_structure\") or {}\n",
    "    from_text = math_struct.get(\"from_text\") or {}\n",
    "    from_solution = math_struct.get(\"from_solution\") or {}\n",
    "    exec_ = attempt.get(\"exec\") or {}\n",
    "    result = attempt.get(\"result\") or {}\n",
    "\n",
    "    code = attempt.get(\"code\") or \"\"\n",
    "\n",
    "    # code_runtime_ms: exec.duration is in seconds -> convert to ms\n",
    "    duration_sec = exec_.get(\"duration\")\n",
    "    code_runtime_ms = int(duration_sec * 1000) if isinstance(duration_sec, (int, float)) else None\n",
    "\n",
    "    code_generated_tokens = tokenizer_fn(code) if tokenizer_fn and code else None\n",
    "\n",
    "    flat = {\n",
    "        # ── Identity ──────────────────────────────────\n",
    "        \"id\": str(uuid.uuid4()),\n",
    "        \"source_license\": record.get(\"license\"),\n",
    "        \"timestamp\": record.get(\"timestamp\"),\n",
    "\n",
    "        # ── Problem definition ────────────────────────\n",
    "        \"domain\": from_text.get(\"domain\"),\n",
    "        \"level\": _lowest_passing_level(record),\n",
    "        \"text\": problem.get(\"text\"),\n",
    "        \"solution\": problem.get(\"original_solution\"),\n",
    "        \"expected_answer\": problem.get(\"expected_answer\"),\n",
    "\n",
    "        # ── Math structure (from text) ────────────────\n",
    "        \"objects\": from_text.get(\"objects\"),\n",
    "        \"constraints\": from_text.get(\"constraints\"),\n",
    "\n",
    "        # ── Math structure (from solution) ────────────\n",
    "        \"reasoning_depth\": from_solution.get(\"reasoning_depth\"),\n",
    "        \"technique_transitions\": from_solution.get(\"technique_transitions\"),\n",
    "        \"reasoning_scope\": from_solution.get(\"reasoning_scope\"),\n",
    "        \"intermediate_reuse\": from_solution.get(\"intermediate_reuse\"),\n",
    "\n",
    "        # ── Code artifact & telemetry ─────────────────\n",
    "        \"code\": code or None,\n",
    "        \"code_attempts\": outcome.get(\"execution_attempts\"),\n",
    "        \"code_runtime_ms\": code_runtime_ms,\n",
    "        \"code_generated_tokens\": code_generated_tokens,\n",
    "        \"code_predicted_correct_answer\": result.get(\"correct\"),\n",
    "    }\n",
    "    return flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "_tokenizer_fn = None\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "_tokenizer_fn = lambda code: len(enc.encode(code, disallowed_special=())) if code else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert and write normalized output (read-only: original dataset is not modified)\n",
    "out_path = RUN_DIR / OUTPUT_FILENAME\n",
    "normalized = []\n",
    "for rec in datapoints:\n",
    "    flat = record_to_flat(rec, tokenizer_fn=_tokenizer_fn)\n",
    "    if flat is not None:\n",
    "        normalized.append(flat)\n",
    "\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for rec in normalized:\n",
    "        f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Read: {len(datapoints)} records from {jsonl_file}\")\n",
    "print(f\"Written: {len(normalized)} records to {out_path}\")\n",
    "print(f\"Skipped (no successful attempt): {len(datapoints) - len(normalized)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview first normalized record\n",
    "if normalized:\n",
    "    print(json.dumps(normalized[1], indent=2, ensure_ascii=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
