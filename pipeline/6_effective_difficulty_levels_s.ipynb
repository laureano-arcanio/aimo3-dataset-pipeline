{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# 6 - Effective Difficulty Levels\n",
    "\n",
    "Resolves the definitive computational bucket and computes a continuous\n",
    "effective-difficulty score for every record.\n",
    "\n",
    "**Pipeline**:\n",
    "1. Load dataset (same JSONL as other pipeline notebooks).\n",
    "2. For each record, find the **definitive bucket level** from `computation_buckets`:\n",
    "   loop over the array, find the lowest level where `passes >= 1`.\n",
    "3. Compute a **mixed difficulty** score combining bucket level, text structure,\n",
    "   and solution structure signals using the specified mixed_difficulty function.\n",
    "4. Build a quantile mapper using quintile buckets (1-5) from the score distribution.\n",
    "5. Write `effective_difficulty: { level, score }` into each record and save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Dict, List, Optional\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  /home/larcanio/AIMO3_v2/data/datasets/Dataset_Full/bucketed/dataset_1_5_complete.jsonl\n",
      "Output: /home/larcanio/AIMO3_v2/data/datasets/Dataset_Full/bucketed/dataset_1_5_complete_effective_difficulty.jsonl\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "INPUT_JSONL_PATH = Path(\"/home/larcanio/AIMO3_v2/data/datasets/Dataset_Full/bucketed/dataset_1_5_complete.jsonl\")\n",
    "OUTPUT_JSONL_PATH = INPUT_JSONL_PATH.parent / \"dataset_1_5_complete_effective_difficulty.jsonl\"\n",
    "\n",
    "# Only process records with these tiers (None = process all)\n",
    "PROCESSABLE_TIERS = None\n",
    "\n",
    "print(f\"Input:  {INPUT_JSONL_PATH}\")\n",
    "print(f\"Output: {OUTPUT_JSONL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 71832 records\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LOAD DATASET\n",
    "# ============================================================================\n",
    "\n",
    "all_records: List[Dict[str, Any]] = []\n",
    "with open(INPUT_JSONL_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line_num, line in enumerate(f, 1):\n",
    "        if line.strip():\n",
    "            try:\n",
    "                all_records.append(json.loads(line))\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing line {line_num}: {e}\")\n",
    "\n",
    "print(f\"Loaded {len(all_records)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "definitive_bucket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definitive bucket level distribution:\n",
      "  level=0: 571\n",
      "  level=1: 2152\n",
      "  level=2: 10516\n",
      "  level=3: 7295\n",
      "  level=4: 2363\n",
      "  level=5: 1080\n",
      "  level=6: 6\n",
      "  level=None: 47849\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DEFINITIVE BUCKET LEVEL\n",
    "# ============================================================================\n",
    "\n",
    "def get_definitive_bucket_level(record: Dict[str, Any]) -> Optional[int]:\n",
    "    \"\"\"Find the lowest computation_buckets level where passes >= 1.\n",
    "\n",
    "    Returns None when the array is missing or no level passed.\n",
    "    \"\"\"\n",
    "    buckets = record.get(\"computation_buckets\")\n",
    "    if not isinstance(buckets, list) or len(buckets) == 0:\n",
    "        return None\n",
    "\n",
    "    best = None\n",
    "    for entry in buckets:\n",
    "        passes = entry.get(\"passes\", 0)\n",
    "        level = entry.get(\"level\")\n",
    "        if level is None:\n",
    "            continue\n",
    "        # passes is an integer count (0 = fail, >= 1 = success)\n",
    "        if isinstance(passes, (int, float)) and passes >= 1:\n",
    "            if best is None or level < best:\n",
    "                best = level\n",
    "    return best\n",
    "\n",
    "\n",
    "# Quick sanity check\n",
    "from collections import Counter\n",
    "levels = [get_definitive_bucket_level(r) for r in all_records]\n",
    "level_counts = Counter(levels)\n",
    "print(\"Definitive bucket level distribution:\")\n",
    "for lvl in sorted(level_counts, key=lambda x: (x is None, x)):\n",
    "    print(f\"  level={lvl}: {level_counts[lvl]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "mixed_difficulty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixed_difficulty defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# MIXED DIFFICULTY SCORE\n",
    "# ============================================================================\n",
    "\n",
    "def mixed_difficulty(B, from_text, from_solution):\n",
    "    \"\"\"\n",
    "    Compute mixed difficulty score combining bucket level (B), text structure, \n",
    "    and solution structure.\n",
    "    \n",
    "    Args:\n",
    "        B: bucket level (int or None)\n",
    "        from_text: dict with mechanisms, constraints, objects\n",
    "        from_solution: dict with reasoning features\n",
    "    \n",
    "    Returns:\n",
    "        float in [0, 6]\n",
    "    \"\"\"\n",
    "    # Default bucket level to 2 if None\n",
    "    if B is None:\n",
    "        B = 2\n",
    "    \n",
    "    # Text structure contribution\n",
    "    from_text = from_text or {}\n",
    "    m = len(from_text.get(\"mechanisms\") or [])\n",
    "    c = len(from_text.get(\"constraints\") or [])\n",
    "    o = len(from_text.get(\"objects\") or [])\n",
    "    \n",
    "    delta_text = 0.30 * m + 0.10 * max(0, c - 1) + 0.05 * max(0, o - 1)\n",
    "    \n",
    "    # Solution structure contribution\n",
    "    from_solution = from_solution or {}\n",
    "    \n",
    "    depth = from_solution.get(\"reasoning_depth\") or \"medium\"\n",
    "    w_d = {\"shallow\": -0.15, \"medium\": 0.0, \"deep\": 0.30}.get(depth, 0.0)\n",
    "    \n",
    "    cs = from_solution.get(\"case_split\") or \"none\"\n",
    "    w_cs = {\"none\": 0.0, \"binary\": 0.15, \"multi\": 0.30}.get(cs, 0.0)\n",
    "    \n",
    "    rs = from_solution.get(\"reasoning_shape\") or \"linear\"\n",
    "    w_rs = {\"linear\": 0.0, \"branching\": 0.20}.get(rs, 0.0)\n",
    "    \n",
    "    tt_raw = from_solution.get(\"technique_transitions\")\n",
    "    try:\n",
    "        w_t = 0.10 * min(int(tt_raw), 3)\n",
    "    except (TypeError, ValueError):\n",
    "        w_t = 0.0\n",
    "    \n",
    "    inv = from_solution.get(\"invariant\") or \"none\"\n",
    "    w_inv = {\"none\": 0.0, \"implicit\": 0.15, \"explicit\": 0.30}.get(inv, 0.0)\n",
    "    \n",
    "    scope = from_solution.get(\"reasoning_scope\") or \"local\"\n",
    "    w_sc = {\"local\": 0.0, \"global\": 0.15}.get(scope, 0.0)\n",
    "    \n",
    "    w_pr = 0.10 if bool(from_solution.get(\"dead_end_pruning\")) else 0.0\n",
    "    \n",
    "    reuse = from_solution.get(\"intermediate_reuse\") or \"single\"\n",
    "    w_reuse = {\"single\": 0.0, \"multiple\": 0.10}.get(reuse, 0.0)\n",
    "    \n",
    "    delta_sol = w_d + w_cs + w_rs + w_t + w_inv + w_sc + w_pr + w_reuse\n",
    "    \n",
    "    # Combine and clip to [0, 6]\n",
    "    D = B + delta_text + delta_sol\n",
    "    if D < 0:\n",
    "        D = 0.0\n",
    "    if D > 6:\n",
    "        D = 6.0\n",
    "    \n",
    "    return D\n",
    "\n",
    "\n",
    "print(\"mixed_difficulty defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "quantile_mapper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_quantile_mapper defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# BUILD QUANTILE MAPPER\n",
    "# ============================================================================\n",
    "\n",
    "def build_quantile_mapper(D_values):\n",
    "    \"\"\"\n",
    "    Build a quantile mapper that maps difficulty scores to levels 1-5.\n",
    "    \n",
    "    Args:\n",
    "        D_values: array of difficulty scores\n",
    "    \n",
    "    Returns:\n",
    "        tuple of (quantiles, mapper_function)\n",
    "        - quantiles: array of 20th, 40th, 60th, 80th percentiles\n",
    "        - mapper_function: function that maps a score to level 1-5\n",
    "    \"\"\"\n",
    "    qs = np.quantile(D_values, [0.2, 0.4, 0.6, 0.8])\n",
    "    \n",
    "    def map_D(D):\n",
    "        if D <= qs[0]:\n",
    "            return 1\n",
    "        if D <= qs[1]:\n",
    "            return 2\n",
    "        if D <= qs[2]:\n",
    "            return 3\n",
    "        if D <= qs[3]:\n",
    "            return 4\n",
    "        return 5\n",
    "    \n",
    "    return qs, map_D\n",
    "\n",
    "\n",
    "print(\"build_quantile_mapper defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "process",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3c4cd27a404e8abcc0f7b35305a590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing raw scores:   0%|          | 0/71832 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computed raw scores for 71832 eligible records\n",
      "Score range: [0.000, 6.000]\n",
      "Mean: 2.418, Median: 2.250\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# COMPUTE EFFECTIVE DIFFICULTY\n",
    "# ============================================================================\n",
    "\n",
    "def get_tier(record: Dict[str, Any]) -> Optional[str]:\n",
    "    return (record.get(\"audit\", {}).get(\"tier\") or record.get(\"tier\", \"\")).lower() or None\n",
    "\n",
    "\n",
    "# --- Pass 1: compute raw mixed_difficulty for eligible records ---\n",
    "raw_scores: List[float] = []\n",
    "record_scores: List[Optional[float]] = []  # parallel to all_records\n",
    "record_levels: List[Optional[int]] = []\n",
    "\n",
    "for record in tqdm(all_records, desc=\"Computing raw scores\"):\n",
    "    tier = get_tier(record)\n",
    "    if PROCESSABLE_TIERS and tier not in PROCESSABLE_TIERS:\n",
    "        record_scores.append(None)\n",
    "        record_levels.append(None)\n",
    "        continue\n",
    "\n",
    "    bl = get_definitive_bucket_level(record)\n",
    "    ms = record.get(\"math_structure\") or {}\n",
    "    from_text = ms.get(\"from_text\")\n",
    "    from_solution = ms.get(\"from_solution\")\n",
    "\n",
    "    score = mixed_difficulty(bl, from_text, from_solution)\n",
    "    raw_scores.append(score)\n",
    "    record_scores.append(score)\n",
    "    record_levels.append(bl)\n",
    "\n",
    "print(f\"\\nComputed raw scores for {len(raw_scores)} eligible records\")\n",
    "if raw_scores:\n",
    "    print(f\"Score range: [{min(raw_scores):.3f}, {max(raw_scores):.3f}]\")\n",
    "    print(f\"Mean: {np.mean(raw_scores):.3f}, Median: {np.median(raw_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "apply_quantile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile thresholds: [2.05 2.2  2.35 2.75]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae3211a36ee4a608c9e6d386208ed94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing effective_difficulty:   0%|          | 0/71832 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Written: 71832, Skipped: 0\n"
     ]
    }
   ],
   "source": [
    "# --- Pass 2: build quantile mapper and write effective_difficulty ---\n",
    "if not raw_scores:\n",
    "    raise RuntimeError(\"No eligible records found â€” check input data and filters.\")\n",
    "\n",
    "quantiles, mapper = build_quantile_mapper(np.array(raw_scores))\n",
    "\n",
    "print(f\"Quantile thresholds: {quantiles}\")\n",
    "\n",
    "written = 0\n",
    "skipped = 0\n",
    "\n",
    "for i, record in enumerate(tqdm(all_records, desc=\"Writing effective_difficulty\")):\n",
    "    score_raw = record_scores[i]\n",
    "    level = record_levels[i]\n",
    "    if score_raw is None:\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    record[\"effective_difficulty\"] = {\n",
    "        \"level\": level,\n",
    "        \"score\": mapper(score_raw),\n",
    "    }\n",
    "    written += 1\n",
    "\n",
    "print(f\"\\nWritten: {written}, Skipped: {skipped}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "save",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 71832 records to /home/larcanio/AIMO3_v2/data/datasets/Dataset_Full/bucketed/dataset_1_5_complete_effective_difficulty.jsonl\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SAVE OUTPUT\n",
    "# ============================================================================\n",
    "\n",
    "OUTPUT_JSONL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "tmp = OUTPUT_JSONL_PATH.with_suffix(\".tmp\")\n",
    "with open(tmp, \"w\", encoding=\"utf-8\") as f:\n",
    "    for record in all_records:\n",
    "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "tmp.rename(OUTPUT_JSONL_PATH)\n",
    "\n",
    "print(f\"Saved {len(all_records)} records to {OUTPUT_JSONL_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "stats",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records with effective_difficulty: 71832\n",
      "\n",
      "Definitive bucket level distribution:\n",
      "  level=0: 571 (0.8%)\n",
      "  level=1: 2152 (3.0%)\n",
      "  level=2: 10516 (14.6%)\n",
      "  level=3: 7295 (10.2%)\n",
      "  level=4: 2363 (3.3%)\n",
      "  level=5: 1080 (1.5%)\n",
      "  level=6: 6 (0.0%)\n",
      "  level=None: 47849 (66.6%)\n",
      "\n",
      "Mapped difficulty score distribution (1-5):\n",
      "  score=1: 15991 (22.3%)\n",
      "  score=2: 15547 (21.6%)\n",
      "  score=3: 11829 (16.5%)\n",
      "  score=4: 14563 (20.3%)\n",
      "  score=5: 13902 (19.4%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'gsm8k_0_20260206_000',\n",
       " 'dataset': 'gsm8k',\n",
       " 'problem_id': '0',\n",
       " 'timestamp': '2026-02-06T20:39:18.551213',\n",
       " 'problem': {'text': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?',\n",
       "  'expected_answer': '72',\n",
       "  'original_solution': 'Natalia sold 48/2 = <<48/2=24>>24 clips in May.\\nNatalia sold 48+24 = <<48+24=72>>72 clips altogether in April and May.'},\n",
       " 'prompt_ids': {'base': 'base_prompt_v1',\n",
       "  'timeout_repair': 'timeout_repair_prompt_v1',\n",
       "  'error_repair': 'error_repair_prompt_v1',\n",
       "  'wrong_answer_repair': 'wrong_answer_repair_prompt_v1',\n",
       "  'reasoning_summary': None},\n",
       " 'models': {'generating': 'gpt-oss', 'fixing': 'gpt-oss'},\n",
       " 'generation_config': {'temperature': 1,\n",
       "  'max_tokens': 3072,\n",
       "  'reasoning_effort': 'low'},\n",
       " 'reasoning_summary_config': {'enabled': False,\n",
       "  'reasoning_effort': None,\n",
       "  'max_tokens': None},\n",
       " 'attempts': [{'n': 1,\n",
       "   'stage': 'initial',\n",
       "   'model': 'gpt-oss',\n",
       "   'timestamp': '2026-02-06T20:39:18.551359',\n",
       "   'code': 'a = 48\\nb = a // 2\\ntotal = a + b\\nprint(total)',\n",
       "   'exec': {'status': 'success',\n",
       "    'stdout': '72',\n",
       "    'stderr': None,\n",
       "    'error': None,\n",
       "    'error_type': None,\n",
       "    'timeout': False,\n",
       "    'duration': 0.020006418228149414},\n",
       "   'result': {'predicted': '72', 'correct': True},\n",
       "   'retry_reason': None}],\n",
       " 'outcome': {'status': 'success',\n",
       "  'answer': '72',\n",
       "  'total_attempts': 1,\n",
       "  'execution_attempts': 1,\n",
       "  'answer_retry_attempts': 0,\n",
       "  'pass_at_k': 1},\n",
       " 'math_structure': {'from_text': {'domain': 'algebra',\n",
       "   'objects': ['positive_integer'],\n",
       "   'constraints': ['equality'],\n",
       "   'mechanisms': [],\n",
       "   'output_type': 'exact_value'},\n",
       "  'from_solution': {'reasoning_shape': 'linear',\n",
       "   'case_split': 'none',\n",
       "   'invariant': 'none',\n",
       "   'auxiliary_construction': 'none',\n",
       "   'reasoning_depth': 'shallow',\n",
       "   'technique_transitions': 0,\n",
       "   'argument_style': 'direct',\n",
       "   'reasoning_scope': 'local',\n",
       "   'dead_end_pruning': False,\n",
       "   'intermediate_reuse': 'none'}},\n",
       " 'extraction_timestamp': '2026-02-07T11:03:26.783816',\n",
       " 'extraction_model': 'gpt-oss',\n",
       " 'extraction_reasoning_effort': 'low',\n",
       " 'extraction_tokens': {'prompt': 2250, 'completion': 211},\n",
       " 'computation_buckets': [{'level': 1,\n",
       "   'model': 'qwen2.5-coder-1.5b',\n",
       "   'attempts': 1,\n",
       "   'passes': 0,\n",
       "   'max_tokens': 64,\n",
       "   'execution_timeout': 1},\n",
       "  {'level': 2,\n",
       "   'model': 'qwen2.5-coder-3b',\n",
       "   'attempts': 1,\n",
       "   'passes': 1,\n",
       "   'max_tokens': 123,\n",
       "   'execution_timeout': 2}],\n",
       " 'effective_difficulty': {'level': 2, 'score': 1}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SUMMARY STATISTICS\n",
    "# ============================================================================\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "ed_records = [r for r in all_records if \"effective_difficulty\" in r]\n",
    "levels_out = [r[\"effective_difficulty\"][\"level\"] for r in ed_records]\n",
    "scores_out = [r[\"effective_difficulty\"][\"score\"] for r in ed_records]\n",
    "\n",
    "print(f\"Records with effective_difficulty: {len(ed_records)}\")\n",
    "\n",
    "# Bucket level distribution\n",
    "print(\"\\nDefinitive bucket level distribution:\")\n",
    "for lvl, cnt in sorted(Counter(levels_out).items(), key=lambda x: (x[0] is None, x[0])):\n",
    "    print(f\"  level={lvl}: {cnt} ({cnt/len(ed_records)*100:.1f}%)\")\n",
    "\n",
    "# Mapped difficulty score distribution (1-5)\n",
    "print(\"\\nMapped difficulty score distribution (1-5):\")\n",
    "for score_level, cnt in sorted(Counter(scores_out).items()):\n",
    "    print(f\"  score={score_level}: {cnt} ({cnt/len(ed_records)*100:.1f}%)\")\n",
    "\n",
    "all_records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "sample",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- level=0 | score=1.0000 ---\n",
      "  id: numina1.5_2369_20260202_2370\n",
      "  dataset: numina1.5\n",
      "  problem: 6 books are aligned in a library. How many ways are there to arrange them....\n",
      "\n",
      "--- level=1 | score=1.0000 ---\n",
      "  id: gsm8k_795_20260206_795\n",
      "  dataset: gsm8k\n",
      "  problem: A movie theater has 6 screens which show movies back-to-back all day. If the movie theater is open for 8 hours, and each...\n",
      "\n",
      "--- level=2 | score=3.0000 ---\n",
      "  id: numina1.5_3606_20260202_3607\n",
      "  dataset: numina1.5\n",
      "  problem: 2. Find the smallest natural number that has exactly 12 different natural divisors, the largest prime divisor of which i...\n",
      "\n",
      "--- level=3 | score=5.0000 ---\n",
      "  id: numina1.5_14_20260203_015\n",
      "  dataset: numina1.5:cn_contest\n",
      "  problem: Example 21. How many three-digit numbers can be formed using $0,1,2,3,4,5$ without repeating any digit?...\n",
      "\n",
      "--- level=4 | score=5.0000 ---\n",
      "  id: numina1.5_3566_20260202_3567\n",
      "  dataset: numina1.5\n",
      "  problem: 13.437 What whole positive number should 180 be divided by, so that the remainder is $25\\%$ of the quotient?...\n",
      "\n",
      "--- level=5 | score=5.0000 ---\n",
      "  id: numina1.5_1579_20260203_1580\n",
      "  dataset: numina1.5:metamath\n",
      "  problem: If Mrs. Lopez needs to buy movie tickets for her husband, herself, her parents (ages 72 and 75), and her three children ...\n",
      "\n",
      "--- level=6 | score=5.0000 ---\n",
      "  id: gsm8k_6118_20260206_6118\n",
      "  dataset: gsm8k\n",
      "  problem: Tomas is hoping to run a marathon next year, which is 26.3 miles. He knows that each month he trains, he can run twice a...\n",
      "\n",
      "--- level=None | score=3.0000 ---\n",
      "  id: numina1.5_970_20260202_971\n",
      "  dataset: numina1.5\n",
      "  problem: Problem 3. In the park, there were lindens and maples. Maples among them were $60 \\%$. In spring, lindens were planted i...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SAMPLE INSPECTION\n",
    "# ============================================================================\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "# Show one example per bucket level\n",
    "by_level: Dict[Optional[int], List] = {}\n",
    "for r in ed_records:\n",
    "    lvl = r[\"effective_difficulty\"][\"level\"]\n",
    "    by_level.setdefault(lvl, []).append(r)\n",
    "\n",
    "for lvl in sorted(by_level, key=lambda x: (x is None, x)):\n",
    "    sample = random.choice(by_level[lvl])\n",
    "    print(f\"--- level={lvl} | score={sample['effective_difficulty']['score']:.4f} ---\")\n",
    "    print(f\"  id: {sample.get('id', 'N/A')}\")\n",
    "    print(f\"  dataset: {sample.get('dataset', 'N/A')}\")\n",
    "    text = sample.get('problem', {}).get('text', '')[:120]\n",
    "    print(f\"  problem: {text}...\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
