{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "import time\n",
        "import multiprocessing as mp\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import anyio\n",
        "import httpx\n",
        "from tqdm.notebook import tqdm\n",
        "from utils import RuntimeConfig, LLMPool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[config] reloaded: MAX_ANSWER_RETRIES: 1 -> 3, EXECUTION_TIMEOUT_SECONDS: 2 -> 20, MAX_CONCURRENT_REQUESTS: 30 -> 100\n",
            "RuntimeConfig(MAX_EXECUTION_RETRIES=1, MAX_ANSWER_RETRIES=3, LLM_REQUEST_RETRY_COUNT=2, LLM_REQUEST_TIMEOUT_SECONDS=300, EXECUTION_TIMEOUT_SECONDS=20, MAX_CONCURRENT_REQUESTS=100)\n",
            "Level filters: LOWER_LEVEL=0, MODEL_LEVEL=5, UPPER_LEVEL=None\n",
            "CURRENT_LEVEL_FAIL_RERUN=True\n"
          ]
        }
      ],
      "source": [
        "# Paths\n",
        "INPUT_DATASET_PATH = Path('/home/larcanio/AIMO3_v2/data/datasets/Dataset_Full/bucketed/dataset_1_5_complete_effective_difficulty.jsonl.jsonl')\n",
        "OUTPUT_DATASET_PATH = Path('/home/larcanio/AIMO3_v2/data/datasets/Dataset_Full/bucketed/dataset_1_5_rerun_more_tokens.jsonl')\n",
        "\n",
        "AUDIT_FIELD_NAME = \"computation_buckets\"\n",
        "\n",
        "# API Configuration\n",
        "API_BASE_URL = \"http://127.0.0.1:8080/v1\"\n",
        "API_KEY = \"sk-local\"\n",
        "MODEL_NAME = \"gpt-oss\"\n",
        "MODEL_LABEL = \"gpt-oss-20b-low\"\n",
        "MODEL_LEVEL = 5\n",
        "\n",
        "# Level filters (None = no filter)\n",
        "UPPER_LEVEL = None\n",
        "LOWER_LEVEL = 0\n",
        "\n",
        "MAX_TOKENS = 256\n",
        "\n",
        "# Sampling configuration\n",
        "N_SAMPLES = 1\n",
        "if N_SAMPLES not in (1, 2):\n",
        "    raise ValueError(f\"N_SAMPLES must be 1 or 2, got {N_SAMPLES}\")\n",
        "\n",
        "ATTEMPT_TEMPERATURE = [0.0, 0.6]\n",
        "ATTEMPT_TOP_P = [1.0, 0.9]\n",
        "\n",
        "CURRENT_LEVEL_FAIL_RERUN = True\n",
        "KEEP_ONLY = True\n",
        "N_PROBLEMS = 0\n",
        "\n",
        "# Validate level bounds\n",
        "if LOWER_LEVEL is not None and LOWER_LEVEL >= MODEL_LEVEL:\n",
        "    raise ValueError(f\"LOWER_LEVEL ({LOWER_LEVEL}) must be < MODEL_LEVEL ({MODEL_LEVEL})\")\n",
        "if UPPER_LEVEL is not None and UPPER_LEVEL <= MODEL_LEVEL:\n",
        "    raise ValueError(f\"UPPER_LEVEL ({UPPER_LEVEL}) must be > MODEL_LEVEL ({MODEL_LEVEL})\")\n",
        "\n",
        "# Runtime configuration\n",
        "CONFIG_FILE = \"config.json\"\n",
        "cfg = RuntimeConfig(CONFIG_FILE, defaults={\n",
        "    \"MAX_EXECUTION_RETRIES\": 1,\n",
        "    \"MAX_ANSWER_RETRIES\": 1,\n",
        "    \"LLM_REQUEST_RETRY_COUNT\": 2,\n",
        "    \"LLM_REQUEST_TIMEOUT_SECONDS\": 300,\n",
        "    \"EXECUTION_TIMEOUT_SECONDS\": 2,\n",
        "    \"MAX_CONCURRENT_REQUESTS\": 30,\n",
        "})\n",
        "\n",
        "print(f\"Configuration: {cfg}\")\n",
        "print(f\"Level filters: LOWER={LOWER_LEVEL}, MODEL={MODEL_LEVEL}, UPPER={UPPER_LEVEL}\")\n",
        "print(f\"Rerun failures: {CURRENT_LEVEL_FAIL_RERUN}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m line.strip():\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m         full_datapoints.append(\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m json.JSONDecodeError:\n\u001b[32m      8\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    333\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m     end = _w(s, end).end()\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/decoder.py:353\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    344\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[33;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[33;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    350\u001b[39m \n\u001b[32m    351\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "full_datapoints = []\n",
        "with open(INPUT_DATASET_PATH, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        if line.strip():\n",
        "            try:\n",
        "                full_datapoints.append(json.loads(line))\n",
        "            except json.JSONDecodeError:\n",
        "                continue\n",
        "\n",
        "print(f\"Loaded: {len(full_datapoints)} total records\")\n",
        "\n",
        "\n",
        "def get_tier(dp: dict) -> str:\n",
        "    \"\"\"Extract tier from audit field.\"\"\"\n",
        "    return dp.get('audit', {}).get('tier', 'core')\n",
        "\n",
        "\n",
        "all_datapoints = full_datapoints\n",
        "if KEEP_ONLY:\n",
        "    all_datapoints = [dp for dp in full_datapoints if get_tier(dp) in ['core', 'extended']]\n",
        "\n",
        "if N_PROBLEMS > 0:\n",
        "    all_datapoints = all_datapoints[:N_PROBLEMS]\n",
        "\n",
        "print(f\"Eligible for classification: {len(all_datapoints)}\")\n",
        "if KEEP_ONLY:\n",
        "    dropped = len(full_datapoints) - len(all_datapoints)\n",
        "    print(f\"Filtered out: {dropped} (tier not in core/extended)\")\n",
        "\n",
        "\n",
        "def _get_audit_list(dp: dict) -> list:\n",
        "    \"\"\"Return audit entries as a list (handles missing or legacy dict format).\"\"\"\n",
        "    audit = dp.get(AUDIT_FIELD_NAME)\n",
        "    if isinstance(audit, list):\n",
        "        return audit\n",
        "    return []\n",
        "\n",
        "\n",
        "def needs_classification(dp: dict) -> bool:\n",
        "    \"\"\"Decide whether to classify this datapoint at MODEL_LEVEL.\n",
        "\n",
        "    Skip rules (in order):\n",
        "      1. Already has an entry at MODEL_LEVEL:\n",
        "         - CURRENT_LEVEL_FAIL_RERUN=False → skip (already processed).\n",
        "         - CURRENT_LEVEL_FAIL_RERUN=True  → skip only if it passed; retry failures.\n",
        "      2. LOWER_LEVEL filter (only when set): if any level in [LOWER_LEVEL, MODEL_LEVEL) passed → skip.\n",
        "         (Problem is too easy — a weaker model already solved it.)\n",
        "         If LOWER_LEVEL is None, no lower-bound filtering is applied.\n",
        "      3. UPPER_LEVEL filter: if no level in (MODEL_LEVEL, UPPER_LEVEL] passed → skip.\n",
        "         (No evidence a stronger model can solve it — don't waste compute.)\n",
        "    \"\"\"\n",
        "    entries = _get_audit_list(dp)\n",
        "\n",
        "    # 1. Current-level check\n",
        "    for entry in entries:\n",
        "        if entry.get('level') == MODEL_LEVEL:\n",
        "            if CURRENT_LEVEL_FAIL_RERUN:\n",
        "                # skip only if it already passed; allow rerun of failures\n",
        "                if entry.get('passes', 0) > 0:\n",
        "                    return False\n",
        "            else:\n",
        "                return False\n",
        "\n",
        "    # 2. Lower-bound filter (only when LOWER_LEVEL is explicitly set)\n",
        "    if LOWER_LEVEL is not None:\n",
        "        for entry in entries:\n",
        "            lvl = entry.get('level')\n",
        "            if lvl is not None and LOWER_LEVEL <= lvl < MODEL_LEVEL and entry.get('passes', 0) > 0:\n",
        "                return False\n",
        "\n",
        "    # 3. Upper-bound filter\n",
        "    if UPPER_LEVEL is not None:\n",
        "        has_upper_pass = any(\n",
        "            entry.get('level') is not None\n",
        "            and MODEL_LEVEL < entry['level'] <= UPPER_LEVEL\n",
        "            and entry.get('passes', 0) > 0\n",
        "            for entry in entries\n",
        "        )\n",
        "        if not has_upper_pass:\n",
        "            return False\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "to_classify = [dp for dp in all_datapoints if needs_classification(dp)]\n",
        "\n",
        "# to_classify = to_classify[:20000]\n",
        "\n",
        "skipped = len(all_datapoints) - len(to_classify)\n",
        "print(f\"To classify: {len(to_classify)} (skipped {skipped} already processed)\")\n",
        "\n",
        "# Position mapping for incremental save: to_classify[i] -> full_datapoints index\n",
        "_id_to_full_pos = {id(dp): i for i, dp in enumerate(full_datapoints)}\n",
        "classify_to_full_pos = [_id_to_full_pos[id(dp)] for dp in to_classify]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Code Extraction & Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "\n",
        "def extract_code_from_response(text):\n",
        "    if not text:\n",
        "        return None\n",
        "    for pattern in [r'```python\\s*(.*?)\\s*```', r'```\\s*(.*?)\\s*```']:\n",
        "        match = re.search(pattern, text, re.DOTALL)\n",
        "        if match:\n",
        "            return match.group(1).strip()\n",
        "    return None\n",
        "\n",
        "\n",
        "def execute_code_with_timeout(code: str, timeout_seconds: int = 30):\n",
        "    \"\"\"Execute code in a fresh subprocess (no fork, no inherited memory).\"\"\"\n",
        "    tmp_path = None\n",
        "    try:\n",
        "        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n",
        "            f.write(code)\n",
        "            tmp_path = f.name\n",
        "\n",
        "        proc = subprocess.run(\n",
        "            [sys.executable, tmp_path],\n",
        "            capture_output=True, text=True, timeout=timeout_seconds,\n",
        "        )\n",
        "\n",
        "        if proc.returncode != 0:\n",
        "            return None, proc.stderr[:500] or \"Non-zero exit\", False\n",
        "        stdout = proc.stdout.strip()\n",
        "        if stdout:\n",
        "            return stdout.split('\\n')[-1].strip(), None, False\n",
        "        return None, \"No output\", False\n",
        "    except subprocess.TimeoutExpired:\n",
        "        return None, \"Timeout\", True\n",
        "    except Exception as e:\n",
        "        return None, str(e)[:500], False\n",
        "    finally:\n",
        "        if tmp_path:\n",
        "            try:\n",
        "                os.unlink(tmp_path)\n",
        "            except OSError:\n",
        "                pass\n",
        "\n",
        "\n",
        "def check_answer(predicted, expected):\n",
        "    if predicted is None or expected is None:\n",
        "        return False\n",
        "    pred_str = str(predicted).strip()\n",
        "    exp_str = str(expected).strip()\n",
        "    if pred_str == exp_str:\n",
        "        return True\n",
        "    try:\n",
        "        return abs(float(pred_str) - float(exp_str)) < 1e-6\n",
        "    except (ValueError, TypeError):\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prompt Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load prompt templates from files\n",
        "PROMPT_DIR = Path(\"prompts\")\n",
        "PROMPT_TEMPLATE = (PROMPT_DIR / \"nb2_code_generation_simple.md\").read_text(encoding=\"utf-8\")\n",
        "\n",
        "SYSTEM_MESSAGE = \"You are a mathematician writing Python code to solve problems.\"\n",
        "\n",
        "\n",
        "def format_prompt(problem: str) -> str:\n",
        "    \"\"\"Format the problem using the loaded template.\"\"\"\n",
        "    return PROMPT_TEMPLATE.format(problem=problem)\n",
        "\n",
        "\n",
        "print(f\"Loaded prompt template from {PROMPT_DIR / 'nb2_code_generation_simple.md'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Classification Engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SAVE_EVERY = 1000\n",
        "\n",
        "\n",
        "def get_problem_text(dp: dict) -> str:\n",
        "    \"\"\"Extract problem text from datapoint.\"\"\"\n",
        "    if 'problem' in dp and isinstance(dp['problem'], dict):\n",
        "        return dp['problem'].get('text', '')\n",
        "    return dp.get('text') or dp.get('problem') or ''\n",
        "\n",
        "\n",
        "def get_expected_answer(dp: dict) -> str:\n",
        "    \"\"\"Extract expected answer from datapoint.\"\"\"\n",
        "    if 'problem' in dp and isinstance(dp['problem'], dict):\n",
        "        return str(dp['problem'].get('expected_answer', ''))\n",
        "    return str(dp.get('answer_expected') or dp.get('answer') or dp.get('expected_answer') or '')\n",
        "\n",
        "\n",
        "def _save_checkpoint(completed_n: int, total_n: int, save_num: int):\n",
        "    \"\"\"Write full datapoints to disk atomically.\"\"\"\n",
        "    OUTPUT_DATASET_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
        "    tmp = OUTPUT_DATASET_PATH.with_suffix('.tmp')\n",
        "    with open(tmp, 'w', encoding='utf-8') as f:\n",
        "        for dp in full_datapoints:\n",
        "            f.write(json.dumps(dp, ensure_ascii=False) + '\\n')\n",
        "    tmp.rename(OUTPUT_DATASET_PATH)\n",
        "    print(f\"\\n[Checkpoint {save_num}] {completed_n}/{total_n} saved\")\n",
        "\n",
        "\n",
        "async def classify_single_problem(pool: LLMPool, dp: dict, idx: int) -> tuple[int, int, int]:\n",
        "    \"\"\"Run up to N_SAMPLES attempts with early exit on first pass.\n",
        "    \n",
        "    Returns (passes, prompt_tokens, completion_tokens).\n",
        "    \"\"\"\n",
        "    problem_text = get_problem_text(dp)\n",
        "    expected_answer = get_expected_answer(dp)\n",
        "    prompt = format_prompt(problem_text)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
        "        {\"role\": \"user\", \"content\": prompt},\n",
        "    ]\n",
        "\n",
        "    passes = 0\n",
        "    prompt_tokens = 0\n",
        "    completion_tokens = 0\n",
        "    for attempt in range(N_SAMPLES):\n",
        "        try:\n",
        "            resp = await pool.request(\n",
        "                messages,\n",
        "                temperature=ATTEMPT_TEMPERATURE[attempt],\n",
        "                max_tokens=MAX_TOKENS,\n",
        "                top_p=ATTEMPT_TOP_P[attempt],\n",
        "                seed=attempt,\n",
        "            )\n",
        "            prompt_tokens += resp.prompt_tokens\n",
        "            completion_tokens += resp.completion_tokens\n",
        "            code = extract_code_from_response(resp.content)\n",
        "            if code:\n",
        "                result, error, is_timeout = await anyio.to_thread.run_sync(\n",
        "                    execute_code_with_timeout, code, cfg.EXECUTION_TIMEOUT_SECONDS,\n",
        "                )\n",
        "                if error is None and not is_timeout and check_answer(result, expected_answer):\n",
        "                    passes += 1\n",
        "                    break  # early exit: no need for more attempts\n",
        "        except Exception as e:\n",
        "            print(f\"Error (problem {idx}, attempt {attempt}): {type(e).__name__} - {str(e)[:100]}\")\n",
        "\n",
        "    return passes, prompt_tokens, completion_tokens\n",
        "\n",
        "\n",
        "async def run_classification(datapoints: list):\n",
        "    results = []\n",
        "    completed = 0\n",
        "    pass_count = 0\n",
        "    total_prompt_tokens = 0\n",
        "    total_completion_tokens = 0\n",
        "    save_count = 0\n",
        "    total = len(datapoints)\n",
        "\n",
        "    pbar = tqdm(total=total, desc=\"Classifying\")\n",
        "    write_lock = anyio.Lock()\n",
        "    save_lock = anyio.Lock()\n",
        "    spawn_limit = anyio.Semaphore(cfg.MAX_CONCURRENT_REQUESTS * 3)\n",
        "\n",
        "    async def config_reloader(pool):\n",
        "        while True:\n",
        "            await anyio.sleep(60)\n",
        "            cfg.reload()\n",
        "            pool._limiter.total_tokens = cfg.MAX_CONCURRENT_REQUESTS\n",
        "            pool._client.timeout = httpx.Timeout(cfg.LLM_REQUEST_TIMEOUT_SECONDS, connect=30)\n",
        "\n",
        "    async def process_one(pool, idx, dp):\n",
        "        nonlocal completed, pass_count, total_prompt_tokens, total_completion_tokens, save_count\n",
        "\n",
        "        passes, p_tok, c_tok = await classify_single_problem(pool, dp, idx)\n",
        "\n",
        "        new_entry = {\n",
        "            \"level\": MODEL_LEVEL,\n",
        "            \"model\": MODEL_LABEL,\n",
        "            \"attempts\": N_SAMPLES,\n",
        "            \"passes\": passes,\n",
        "            \"max_tokens\": MAX_TOKENS,\n",
        "            \"execution_timeout\": cfg.EXECUTION_TIMEOUT_SECONDS,\n",
        "        }\n",
        "\n",
        "        classified_dp = dp.copy()\n",
        "        existing_audit = _get_audit_list(dp)\n",
        "\n",
        "        if CURRENT_LEVEL_FAIL_RERUN:\n",
        "            # Replace existing entry at MODEL_LEVEL (avoid duplicates on rerun)\n",
        "            existing_audit = [e for e in existing_audit if e.get('level') != MODEL_LEVEL]\n",
        "\n",
        "        existing_audit.append(new_entry)\n",
        "        classified_dp[AUDIT_FIELD_NAME] = existing_audit\n",
        "\n",
        "        should_save = False\n",
        "        async with write_lock:\n",
        "            results.append((idx, classified_dp))\n",
        "            completed += 1\n",
        "            full_datapoints[classify_to_full_pos[idx]] = classified_dp\n",
        "            total_prompt_tokens += p_tok\n",
        "            total_completion_tokens += c_tok\n",
        "            if passes > 0:\n",
        "                pass_count += 1\n",
        "            pbar.set_postfix(pass_rate=f\"{pass_count/completed:.2%}\", done=completed)\n",
        "            pbar.update(1)\n",
        "            should_save = completed % SAVE_EVERY == 0\n",
        "\n",
        "        if should_save:\n",
        "            async with save_lock:\n",
        "                save_count += 1\n",
        "                await anyio.to_thread.run_sync(\n",
        "                    _save_checkpoint, completed, total, save_count,\n",
        "                )\n",
        "\n",
        "    async with LLMPool(\n",
        "        base_url=API_BASE_URL,\n",
        "        api_key=API_KEY,\n",
        "        model=MODEL_NAME,\n",
        "        reasoning_effort=\"low\",\n",
        "        max_inflight=cfg.MAX_CONCURRENT_REQUESTS,\n",
        "        timeout=cfg.LLM_REQUEST_TIMEOUT_SECONDS,\n",
        "    ) as pool:\n",
        "        async with anyio.create_task_group() as tg:\n",
        "            tg.start_soon(config_reloader, pool)\n",
        "\n",
        "            async with anyio.create_task_group() as work_tg:\n",
        "                for idx, dp in enumerate(datapoints):\n",
        "                    await spawn_limit.acquire()\n",
        "                    async def _run(pool=pool, idx=idx, dp=dp):\n",
        "                        try:\n",
        "                            await process_one(pool, idx, dp)\n",
        "                        finally:\n",
        "                            spawn_limit.release()\n",
        "                    work_tg.start_soon(_run)\n",
        "\n",
        "            tg.cancel_scope.cancel()\n",
        "\n",
        "    pbar.close()\n",
        "\n",
        "    # Final save\n",
        "    save_count += 1\n",
        "    _save_checkpoint(completed, total, save_count)\n",
        "\n",
        "    results.sort(key=lambda x: x[0])\n",
        "    classified = [dp for _, dp in results]\n",
        "    token_stats = {\n",
        "        \"prompt_tokens\": total_prompt_tokens,\n",
        "        \"completion_tokens\": total_completion_tokens,\n",
        "        \"total_tokens\": total_prompt_tokens + total_completion_tokens,\n",
        "    }\n",
        "    return classified, token_stats\n",
        "\n",
        "\n",
        "print(\"Classification engine ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## API Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OK: \n"
          ]
        }
      ],
      "source": [
        "async def test_api():\n",
        "    body = {\n",
        "        \"model\": MODEL_NAME,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": \"You are helpful.\"},\n",
        "            {\"role\": \"user\", \"content\": \"What is 2+2? Reply with just the number.\"}\n",
        "        ],\n",
        "        \"temperature\": 0.0,\n",
        "        \"max_tokens\": 32,\n",
        "    }\n",
        "    async with httpx.AsyncClient(timeout=httpx.Timeout(30, connect=5)) as client:\n",
        "        resp = await client.post(\n",
        "            f\"{API_BASE_URL}/chat/completions\",\n",
        "            json=body,\n",
        "            headers={\"Authorization\": f\"Bearer {API_KEY}\", \"Content-Type\": \"application/json\"},\n",
        "        )\n",
        "        if resp.status_code == 200:\n",
        "            data = resp.json()\n",
        "            print(f\"OK: {data['choices'][0]['message']['content']}\")\n",
        "        else:\n",
        "            print(f\"FAIL {resp.status_code}: {resp.text[:200]}\")\n",
        "\n",
        "await test_api()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classifying 13567 problems | level=5 | N_SAMPLES=1 | Model: gpt-oss-20b-low\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "394e59a0e1d74f1bbae0131ec95c90d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Classifying:   0%|          | 0/13567 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[checkpoint 1] 1000/13567 saved to dataset_1_5_rerun_more_tokens_rm.jsonl\n",
            "\n",
            "[checkpoint 2] 2000/13567 saved to dataset_1_5_rerun_more_tokens_rm.jsonl\n"
          ]
        },
        {
          "ename": "CancelledError",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mClassifying \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(to_classify)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m problems | level=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_LEVEL\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | N_SAMPLES=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN_SAMPLES\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_LABEL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m start_time = time.time()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m classified_datapoints, token_stats = \u001b[38;5;28;01mawait\u001b[39;00m run_classification(to_classify)\n\u001b[32m      5\u001b[39m elapsed = time.time() - start_time\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mDone in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed/\u001b[38;5;28mlen\u001b[39m(to_classify)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms/problem)\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 132\u001b[39m, in \u001b[36mrun_classification\u001b[39m\u001b[34m(datapoints)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;28;01mawait\u001b[39;00m anyio.to_thread.run_sync(\n\u001b[32m    121\u001b[39m                 _save_checkpoint, completed, total, save_count,\n\u001b[32m    122\u001b[39m             )\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m LLMPool(\n\u001b[32m    125\u001b[39m     base_url=API_BASE_URL,\n\u001b[32m    126\u001b[39m     api_key=API_KEY,\n\u001b[32m   (...)\u001b[39m\u001b[32m    130\u001b[39m     timeout=cfg.LLM_REQUEST_TIMEOUT_SECONDS,\n\u001b[32m    131\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m anyio.create_task_group() \u001b[38;5;28;01mas\u001b[39;00m tg:\n\u001b[32m    133\u001b[39m         tg.start_soon(config_reloader, pool)\n\u001b[32m    135\u001b[39m         \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m anyio.create_task_group() \u001b[38;5;28;01mas\u001b[39;00m work_tg:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AIMO3_v2/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py:787\u001b[39m, in \u001b[36mTaskGroup.__aexit__\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    783\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m BaseExceptionGroup(\n\u001b[32m    784\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33munhandled errors in a TaskGroup\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._exceptions\n\u001b[32m    785\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m exc_val:\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exc_val\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cancel_scope.\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mtype\u001b[39m(exc), exc, exc.__traceback__):\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 135\u001b[39m, in \u001b[36mrun_classification\u001b[39m\u001b[34m(datapoints)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m anyio.create_task_group() \u001b[38;5;28;01mas\u001b[39;00m tg:\n\u001b[32m    133\u001b[39m     tg.start_soon(config_reloader, pool)\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m anyio.create_task_group() \u001b[38;5;28;01mas\u001b[39;00m work_tg:\n\u001b[32m    136\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m idx, dp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(datapoints):\n\u001b[32m    137\u001b[39m             \u001b[38;5;28;01mawait\u001b[39;00m spawn_limit.acquire()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AIMO3_v2/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py:787\u001b[39m, in \u001b[36mTaskGroup.__aexit__\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    783\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m BaseExceptionGroup(\n\u001b[32m    784\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33munhandled errors in a TaskGroup\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._exceptions\n\u001b[32m    785\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m exc_val:\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exc_val\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cancel_scope.\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mtype\u001b[39m(exc), exc, exc.__traceback__):\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 137\u001b[39m, in \u001b[36mrun_classification\u001b[39m\u001b[34m(datapoints)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m anyio.create_task_group() \u001b[38;5;28;01mas\u001b[39;00m work_tg:\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m idx, dp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(datapoints):\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m spawn_limit.acquire()\n\u001b[32m    138\u001b[39m         \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run\u001b[39m(pool=pool, idx=idx, dp=dp):\n\u001b[32m    139\u001b[39m             \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/AIMO3_v2/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py:1911\u001b[39m, in \u001b[36mSemaphore.acquire\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1909\u001b[39m \u001b[38;5;28mself\u001b[39m._waiters.append(fut)\n\u001b[32m   1910\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[32m   1912\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m CancelledError:\n\u001b[32m   1913\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[31mCancelledError\u001b[39m: "
          ]
        }
      ],
      "source": [
        "print(f\"Classifying {len(to_classify)} problems | level={MODEL_LEVEL} | N_SAMPLES={N_SAMPLES} | Model: {MODEL_LABEL}\\n\")\n",
        "\n",
        "start_time = time.time()\n",
        "classified_datapoints, token_stats = await run_classification(to_classify)\n",
        "elapsed = time.time() - start_time\n",
        "\n",
        "print(f\"\\nDone in {elapsed:.1f}s ({elapsed/len(to_classify):.2f}s/problem)\")\n",
        "print(f\"\\nToken usage:\")\n",
        "print(f\"  Prompt tokens:     {token_stats['prompt_tokens']:,}\")\n",
        "print(f\"  Completion tokens: {token_stats['completion_tokens']:,}\")\n",
        "print(f\"  Total tokens:      {token_stats['total_tokens']:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Level 5 (gpt-oss-20b-low)\n",
            "Total:  36464\n",
            "Passed: 11026 (30.24%)\n",
            "Failed: 25438 (69.76%)\n"
          ]
        }
      ],
      "source": [
        "total = len(classified_datapoints)\n",
        "\n",
        "def _current_level_passes(dp):\n",
        "    for entry in dp.get(AUDIT_FIELD_NAME, []):\n",
        "        if entry.get('level') == MODEL_LEVEL:\n",
        "            return entry.get('passes', 0)\n",
        "    return 0\n",
        "\n",
        "passed = sum(1 for dp in classified_datapoints if _current_level_passes(dp) > 0)\n",
        "failed = total - passed\n",
        "\n",
        "print(f\"Level {MODEL_LEVEL} ({MODEL_LABEL})\")\n",
        "print(f\"Total:  {total}\")\n",
        "print(f\"Passed: {passed} ({passed/total*100:.2f}%)\")\n",
        "print(f\"Failed: {failed} ({failed/total*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Classified Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved 71832 records to /home/larcanio/AIMO3_v2/data/datasets/Dataset_Full/bucketed/dataset_1_5_rerun_more_tokens.jsonl\n",
            "  classified: 36464, unchanged: 35368\n"
          ]
        }
      ],
      "source": [
        "# Merge classified results back into the FULL dataset (preserves all original records)\n",
        "classified_set = {id(dp): cdp for dp, cdp in zip(to_classify, classified_datapoints)}\n",
        "\n",
        "final_datapoints = []\n",
        "for dp in full_datapoints:\n",
        "    if id(dp) in classified_set:\n",
        "        final_datapoints.append(classified_set[id(dp)])\n",
        "    else:\n",
        "        final_datapoints.append(dp)\n",
        "\n",
        "OUTPUT_DATASET_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
        "with open(OUTPUT_DATASET_PATH, 'w', encoding='utf-8') as f:\n",
        "    for dp in final_datapoints:\n",
        "        f.write(json.dumps(dp, ensure_ascii=False) + '\\n')\n",
        "\n",
        "print(f\"Saved {len(final_datapoints)} records to {OUTPUT_DATASET_PATH}\")\n",
        "print(f\"  classified: {len(classified_datapoints)}, unchanged: {len(final_datapoints) - len(classified_datapoints)}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
