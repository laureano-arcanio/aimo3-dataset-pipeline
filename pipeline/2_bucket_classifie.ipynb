{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import anyio\n",
    "import httpx\n",
    "from tqdm.notebook import tqdm\n",
    "from runtime_config import RuntimeConfig\n",
    "from llm_pool import LLMPool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[config] reloaded: MAX_ANSWER_RETRIES: 1 -> 3, LLM_REQUEST_TIMEOUT_SECONDS: 500 -> 800, EXECUTION_TIMEOUT_SECONDS: 2 -> 30\n",
      "RuntimeConfig(MAX_EXECUTION_RETRIES=1, MAX_ANSWER_RETRIES=3, LLM_REQUEST_RETRY_COUNT=2, LLM_REQUEST_TIMEOUT_SECONDS=800, EXECUTION_TIMEOUT_SECONDS=30, MAX_CONCURRENT_REQUESTS=30)\n",
      "Level filters: LOWER_LEVEL=0, MODEL_LEVEL=8, UPPER_LEVEL=None\n",
      "CURRENT_LEVEL_FAIL_RERUN=False\n"
     ]
    }
   ],
   "source": [
    "INPUT_DATASET_PATH = Path('/home/larcanio/AIMO3_v2/data/datasets/Dataset_Full/bucketed/dataset_0_7_continue.jsonl')\n",
    "OUTPUT_DATASET_PATH = Path('/home/larcanio/AIMO3_v2/data/datasets/Dataset_Full/bucketed/dataset_0_8.jsonl')\n",
    "\n",
    "AUDIT_FIELD_NAME = \"computation_buckets\"\n",
    "\n",
    "# MODEL_LEVEL = 0:\n",
    "# MODEL_LABEL = \"qwen2.5-coder-0.5b\"\n",
    "# MAX_TOKENS = 64\n",
    "# EXECUTION_TIMEOUT_SECONDS = 1\n",
    "# MODEL_LEVEL = 1:\n",
    "\n",
    "# MODEL_LABEL = \"qwen2.5-coder-1.5b\"\n",
    "# MAX_TOKENS = 64\n",
    "# EXECUTION_TIMEOUT_SECONDS = 2\n",
    "\n",
    "# MODEL_LEVEL = 2:\n",
    "# MODEL_LABEL = \"qwen2.5-coder-3b\"\n",
    "# MAX_TOKENS = 128\n",
    "# EXECUTION_TIMEOUT_SECONDS = 3\n",
    "\n",
    "# MODEL_LEVEL = 3:\n",
    "# MODEL_LABEL = \"qwen2.5-coder-7b\"\n",
    "# MAX_TOKENS = 256\n",
    "# EXECUTION_TIMEOUT_SECONDS = 4\n",
    "\n",
    "# MODEL_LEVEL = 4:\n",
    "# MODEL_LABEL = \"qwen2.5-coder-14b\"\n",
    "# MAX_TOKENS = 1024\n",
    "# EXECUTION_TIMEOUT_SECONDS = 4\n",
    "\n",
    "# MODEL_LEVEL = 5:\n",
    "# MODEL_LABEL = \"GPT_OSS 20b LOW\"\n",
    "# MAX_TOKENS = 2048\n",
    "# EXECUTION_TIMEOUT_SECONDS = 10\n",
    "\n",
    "# MODEL_LEVEL = 6:\n",
    "# MODEL_LABEL = \"GPT_OSS 20b MED\"\n",
    "# MAX_TOKENS = 2048*2\n",
    "# EXECUTION_TIMEOUT_SECONDS = 15\n",
    "\n",
    "\n",
    "# ❯ No I want to run 4 on everything up else 4. So 5, and 6 \n",
    "\n",
    "# ● Got it — you want to re-run level 4 on problems that are currently bucketed as level 5 or 6\n",
    "#   (passed at 5 or 6 but failed at 4). The notebook already supports this with UPPER_LEVEL:\n",
    "\n",
    "#   MODEL_LEVEL = 4\n",
    "#   CURRENT_LEVEL_FAIL_RERUN = True   # retry level-4 failures\n",
    "#   UPPER_LEVEL = 6                    # only problems where level 5 or 6 passed\n",
    "#   LOWER_LEVEL = 0                    # skip problems already solved by levels 0-3\n",
    "\n",
    "#   The UPPER_LEVEL=6 filter in needs_classification will only include problems where some level\n",
    "#   in (4, 6] (i.e. 5 or 6) has passes > 0. Combined with CURRENT_LEVEL_FAIL_RERUN=True, it skips\n",
    "#   any that already pass at level 4 and retries the rest.\n",
    "\n",
    "#   You'd also want to update the model/token settings to match your level 4 setup (model\n",
    "#   endpoint, MAX_TOKENS, MODEL_LABEL, etc.).\n",
    "\n",
    "\n",
    "API_BASE_URL = \"http://127.0.0.1:8080/v1\"\n",
    "API_KEY = \"sk-local\"\n",
    "MODEL_NAME = \"gpt-oss\"\n",
    "MODEL_LABEL = \"gpt-oss-20b-high\"\n",
    "MODEL_LEVEL = 8\n",
    "\n",
    "# Level filters (None = no filter)\n",
    "# UPPER_LEVEL: only include datapoints where some level in (MODEL_LEVEL, UPPER_LEVEL] passed.\n",
    "#   e.g. MODEL_LEVEL=1, UPPER_LEVEL=5 → only problems a stronger model already solved.\n",
    "# LOWER_LEVEL: only include datapoints where NO level in [LOWER_LEVEL, MODEL_LEVEL) passed.\n",
    "#   e.g. MODEL_LEVEL=5, LOWER_LEVEL=2 → only problems that levels 2-4 all failed (or untested).\n",
    "UPPER_LEVEL = None\n",
    "LOWER_LEVEL = 0\n",
    "\n",
    "MAX_TOKENS = 512*15\n",
    "\n",
    "N_SAMPLES = 1       # attempts per problem (must be 1 or 2)\n",
    "if N_SAMPLES not in (1, 2):\n",
    "    raise ValueError(f\"N_SAMPLES must be 1 or 2, got {N_SAMPLES}\")\n",
    "\n",
    "# Per-attempt sampling params (index 0 = attempt 1, index 1 = attempt 2)\n",
    "ATTEMPT_TEMPERATURE = [0.0, 0.6]\n",
    "ATTEMPT_TOP_P       = [1.0, 0.9]\n",
    "\n",
    "CURRENT_LEVEL_FAIL_RERUN = False  # re-run current-level failures + records with no level entry\n",
    "\n",
    "KEEP_ONLY = True     # only keep core/extended tiers\n",
    "N_PROBLEMS = 0       # 0 = all problems\n",
    "\n",
    "# Validate level bounds\n",
    "if LOWER_LEVEL is not None and LOWER_LEVEL >= MODEL_LEVEL:\n",
    "    raise ValueError(f\"LOWER_LEVEL ({LOWER_LEVEL}) must be < MODEL_LEVEL ({MODEL_LEVEL})\")\n",
    "if UPPER_LEVEL is not None and UPPER_LEVEL <= MODEL_LEVEL:\n",
    "    raise ValueError(f\"UPPER_LEVEL ({UPPER_LEVEL}) must be > MODEL_LEVEL ({MODEL_LEVEL})\")\n",
    "\n",
    "CONFIG_FILE = \"config.json\"\n",
    "cfg = RuntimeConfig(CONFIG_FILE, defaults={\n",
    "    \"MAX_EXECUTION_RETRIES\": 1,\n",
    "    \"MAX_ANSWER_RETRIES\": 1,\n",
    "    \"LLM_REQUEST_RETRY_COUNT\": 2,\n",
    "    \"LLM_REQUEST_TIMEOUT_SECONDS\": 500,\n",
    "    \"EXECUTION_TIMEOUT_SECONDS\": 2,\n",
    "    \"MAX_CONCURRENT_REQUESTS\": 30,\n",
    "})\n",
    "\n",
    "print(cfg)\n",
    "print(f\"Level filters: LOWER_LEVEL={LOWER_LEVEL}, MODEL_LEVEL={MODEL_LEVEL}, UPPER_LEVEL={UPPER_LEVEL}\")\n",
    "print(f\"CURRENT_LEVEL_FAIL_RERUN={CURRENT_LEVEL_FAIL_RERUN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 71832 total records\n",
      "Eligible for classification: 71832\n",
      "Filtered out: 0 (tier not in core/extended)\n",
      "To classify: 16028 (skipped 55804 already processed)\n"
     ]
    }
   ],
   "source": [
    "full_datapoints = []\n",
    "with open(INPUT_DATASET_PATH, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            try:\n",
    "                full_datapoints.append(json.loads(line))\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "\n",
    "print(f\"Loaded: {len(full_datapoints)} total records\")\n",
    "\n",
    "\n",
    "def get_tier(dp: dict) -> str:\n",
    "    \"\"\"Extract tier from audit field.\"\"\"\n",
    "    return dp.get('audit', {}).get('tier', 'core')\n",
    "\n",
    "\n",
    "all_datapoints = full_datapoints\n",
    "if KEEP_ONLY:\n",
    "    all_datapoints = [dp for dp in full_datapoints if get_tier(dp) in ['core', 'extended']]\n",
    "\n",
    "if N_PROBLEMS > 0:\n",
    "    all_datapoints = all_datapoints[:N_PROBLEMS]\n",
    "\n",
    "print(f\"Eligible for classification: {len(all_datapoints)}\")\n",
    "if KEEP_ONLY:\n",
    "    dropped = len(full_datapoints) - len(all_datapoints)\n",
    "    print(f\"Filtered out: {dropped} (tier not in core/extended)\")\n",
    "\n",
    "\n",
    "def _get_audit_list(dp: dict) -> list:\n",
    "    \"\"\"Return audit entries as a list (handles missing or legacy dict format).\"\"\"\n",
    "    audit = dp.get(AUDIT_FIELD_NAME)\n",
    "    if isinstance(audit, list):\n",
    "        return audit\n",
    "    return []\n",
    "\n",
    "\n",
    "def needs_classification(dp: dict) -> bool:\n",
    "    \"\"\"Decide whether to classify this datapoint at MODEL_LEVEL.\n",
    "\n",
    "    Skip rules (in order):\n",
    "      1. Already has an entry at MODEL_LEVEL:\n",
    "         - CURRENT_LEVEL_FAIL_RERUN=False → skip (already processed).\n",
    "         - CURRENT_LEVEL_FAIL_RERUN=True  → skip only if it passed; retry failures.\n",
    "      2. LOWER_LEVEL filter (only when set): if any level in [LOWER_LEVEL, MODEL_LEVEL) passed → skip.\n",
    "         (Problem is too easy — a weaker model already solved it.)\n",
    "         If LOWER_LEVEL is None, no lower-bound filtering is applied.\n",
    "      3. UPPER_LEVEL filter: if no level in (MODEL_LEVEL, UPPER_LEVEL] passed → skip.\n",
    "         (No evidence a stronger model can solve it — don't waste compute.)\n",
    "    \"\"\"\n",
    "    entries = _get_audit_list(dp)\n",
    "\n",
    "    # 1. Current-level check\n",
    "    for entry in entries:\n",
    "        if entry.get('level') == MODEL_LEVEL:\n",
    "            if CURRENT_LEVEL_FAIL_RERUN:\n",
    "                # skip only if it already passed; allow rerun of failures\n",
    "                if entry.get('passes', 0) > 0:\n",
    "                    return False\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "    # 2. Lower-bound filter (only when LOWER_LEVEL is explicitly set)\n",
    "    if LOWER_LEVEL is not None:\n",
    "        for entry in entries:\n",
    "            lvl = entry.get('level')\n",
    "            if lvl is not None and LOWER_LEVEL <= lvl < MODEL_LEVEL and entry.get('passes', 0) > 0:\n",
    "                return False\n",
    "\n",
    "    # 3. Upper-bound filter\n",
    "    if UPPER_LEVEL is not None:\n",
    "        has_upper_pass = any(\n",
    "            entry.get('level') is not None\n",
    "            and MODEL_LEVEL < entry['level'] <= UPPER_LEVEL\n",
    "            and entry.get('passes', 0) > 0\n",
    "            for entry in entries\n",
    "        )\n",
    "        if not has_upper_pass:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "to_classify = [dp for dp in all_datapoints if needs_classification(dp)]\n",
    "\n",
    "# to_classify = to_classify[:20000]\n",
    "\n",
    "skipped = len(all_datapoints) - len(to_classify)\n",
    "print(f\"To classify: {len(to_classify)} (skipped {skipped} already processed)\")\n",
    "\n",
    "# Position mapping for incremental save: to_classify[i] -> full_datapoints index\n",
    "_id_to_full_pos = {id(dp): i for i, dp in enumerate(full_datapoints)}\n",
    "classify_to_full_pos = [_id_to_full_pos[id(dp)] for dp in to_classify]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Extraction & Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "\n",
    "def extract_code_from_response(text):\n",
    "    if not text:\n",
    "        return None\n",
    "    for pattern in [r'```python\\s*(.*?)\\s*```', r'```\\s*(.*?)\\s*```']:\n",
    "        match = re.search(pattern, text, re.DOTALL)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "    return None\n",
    "\n",
    "\n",
    "def execute_code_with_timeout(code: str, timeout_seconds: int = 30):\n",
    "    \"\"\"Execute code in a fresh subprocess (no fork, no inherited memory).\"\"\"\n",
    "    tmp_path = None\n",
    "    try:\n",
    "        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n",
    "            f.write(code)\n",
    "            tmp_path = f.name\n",
    "\n",
    "        proc = subprocess.run(\n",
    "            [sys.executable, tmp_path],\n",
    "            capture_output=True, text=True, timeout=timeout_seconds,\n",
    "        )\n",
    "\n",
    "        if proc.returncode != 0:\n",
    "            return None, proc.stderr[:500] or \"Non-zero exit\", False\n",
    "        stdout = proc.stdout.strip()\n",
    "        if stdout:\n",
    "            return stdout.split('\\n')[-1].strip(), None, False\n",
    "        return None, \"No output\", False\n",
    "    except subprocess.TimeoutExpired:\n",
    "        return None, \"Timeout\", True\n",
    "    except Exception as e:\n",
    "        return None, str(e)[:500], False\n",
    "    finally:\n",
    "        if tmp_path:\n",
    "            try:\n",
    "                os.unlink(tmp_path)\n",
    "            except OSError:\n",
    "                pass\n",
    "\n",
    "\n",
    "def check_answer(predicted, expected):\n",
    "    if predicted is None or expected is None:\n",
    "        return False\n",
    "    pred_str = str(predicted).strip()\n",
    "    exp_str = str(expected).strip()\n",
    "    if pred_str == exp_str:\n",
    "        return True\n",
    "    try:\n",
    "        return abs(float(pred_str) - float(exp_str)) < 1e-6\n",
    "    except (ValueError, TypeError):\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MESSAGE = \"You are a mathematician writing Python code to solve problems.\"\n",
    "\n",
    "\n",
    "def format_prompt(problem: str) -> str:\n",
    "    return f\"\"\"Write a Python program that computes the correct answer to the following math problem.\n",
    "\n",
    "Requirements:\n",
    "- The program must compute the answer programmatically (do NOT hard-code the final value).\n",
    "- The program must be fully self-contained and executable.\n",
    "- The program must print ONLY the final numerical answer (no extra text).\n",
    "\n",
    "Output format:\n",
    "- Output exactly one Python code block, starting with ```python and ending with ```.\n",
    "- Do not include any text outside the code block.\n",
    "\n",
    "Problem:\n",
    "{problem}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification engine ready\n"
     ]
    }
   ],
   "source": [
    "SAVE_EVERY = 1000  # checkpoint every N completions\n",
    "\n",
    "\n",
    "def get_problem_text(dp: dict) -> str:\n",
    "    if 'problem' in dp and isinstance(dp['problem'], dict):\n",
    "        return dp['problem'].get('text', '')\n",
    "    return dp.get('text') or dp.get('problem') or ''\n",
    "\n",
    "\n",
    "def get_expected_answer(dp: dict) -> str:\n",
    "    if 'problem' in dp and isinstance(dp['problem'], dict):\n",
    "        return str(dp['problem'].get('expected_answer', ''))\n",
    "    return str(dp.get('answer_expected') or dp.get('answer') or dp.get('expected_answer') or '')\n",
    "\n",
    "\n",
    "def _save_checkpoint(completed_n: int, total_n: int, save_num: int):\n",
    "    \"\"\"Write full_datapoints to disk atomically (runs in thread).\"\"\"\n",
    "    OUTPUT_DATASET_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    tmp = OUTPUT_DATASET_PATH.with_suffix('.tmp')\n",
    "    with open(tmp, 'w', encoding='utf-8') as f:\n",
    "        for dp in full_datapoints:\n",
    "            f.write(json.dumps(dp, ensure_ascii=False) + '\\n')\n",
    "    tmp.rename(OUTPUT_DATASET_PATH)\n",
    "    print(f\"\\n[checkpoint {save_num}] {completed_n}/{total_n} saved to {OUTPUT_DATASET_PATH.name}\")\n",
    "\n",
    "\n",
    "async def classify_single_problem(pool: LLMPool, dp: dict, idx: int) -> tuple[int, int, int]:\n",
    "    \"\"\"Run up to N_SAMPLES attempts; early-exit on first pass.\n",
    "    Returns (passes, prompt_tokens, completion_tokens).\"\"\"\n",
    "    problem_text = get_problem_text(dp)\n",
    "    expected_answer = get_expected_answer(dp)\n",
    "    prompt = format_prompt(problem_text)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "\n",
    "    passes = 0\n",
    "    prompt_tokens = 0\n",
    "    completion_tokens = 0\n",
    "    for attempt in range(N_SAMPLES):\n",
    "        try:\n",
    "            resp = await pool.request(\n",
    "                messages,\n",
    "                temperature=ATTEMPT_TEMPERATURE[attempt],\n",
    "                max_tokens=MAX_TOKENS,\n",
    "                top_p=ATTEMPT_TOP_P[attempt],\n",
    "                seed=attempt,\n",
    "            )\n",
    "            prompt_tokens += resp.prompt_tokens\n",
    "            completion_tokens += resp.completion_tokens\n",
    "            code = extract_code_from_response(resp.content)\n",
    "            if code:\n",
    "                result, error, is_timeout = await anyio.to_thread.run_sync(\n",
    "                    execute_code_with_timeout, code, cfg.EXECUTION_TIMEOUT_SECONDS,\n",
    "                )\n",
    "                if error is None and not is_timeout and check_answer(result, expected_answer):\n",
    "                    passes += 1\n",
    "                    break  # early exit: no need for more attempts\n",
    "        except Exception as e:\n",
    "            print(f\"Error (problem {idx}, attempt {attempt}): {type(e).__name__} - {str(e)[:100]}\")\n",
    "\n",
    "    return passes, prompt_tokens, completion_tokens\n",
    "\n",
    "\n",
    "async def run_classification(datapoints: list):\n",
    "    results = []\n",
    "    completed = 0\n",
    "    pass_count = 0\n",
    "    total_prompt_tokens = 0\n",
    "    total_completion_tokens = 0\n",
    "    save_count = 0\n",
    "    total = len(datapoints)\n",
    "\n",
    "    pbar = tqdm(total=total, desc=\"Classifying\")\n",
    "    write_lock = anyio.Lock()\n",
    "    save_lock = anyio.Lock()\n",
    "    spawn_limit = anyio.Semaphore(cfg.MAX_CONCURRENT_REQUESTS * 3)\n",
    "\n",
    "    async def config_reloader(pool):\n",
    "        while True:\n",
    "            await anyio.sleep(60)\n",
    "            cfg.reload()\n",
    "            pool._limiter.total_tokens = cfg.MAX_CONCURRENT_REQUESTS\n",
    "            pool._client.timeout = httpx.Timeout(cfg.LLM_REQUEST_TIMEOUT_SECONDS, connect=30)\n",
    "\n",
    "    async def process_one(pool, idx, dp):\n",
    "        nonlocal completed, pass_count, total_prompt_tokens, total_completion_tokens, save_count\n",
    "\n",
    "        passes, p_tok, c_tok = await classify_single_problem(pool, dp, idx)\n",
    "\n",
    "        new_entry = {\n",
    "            \"level\": MODEL_LEVEL,\n",
    "            \"model\": MODEL_LABEL,\n",
    "            \"attempts\": N_SAMPLES,\n",
    "            \"passes\": passes,\n",
    "            \"max_tokens\": MAX_TOKENS,\n",
    "            \"execution_timeout\": cfg.EXECUTION_TIMEOUT_SECONDS,\n",
    "        }\n",
    "\n",
    "        classified_dp = dp.copy()\n",
    "        existing_audit = _get_audit_list(dp)\n",
    "\n",
    "        if CURRENT_LEVEL_FAIL_RERUN:\n",
    "            # Replace existing entry at MODEL_LEVEL (avoid duplicates on rerun)\n",
    "            existing_audit = [e for e in existing_audit if e.get('level') != MODEL_LEVEL]\n",
    "\n",
    "        existing_audit.append(new_entry)\n",
    "        classified_dp[AUDIT_FIELD_NAME] = existing_audit\n",
    "\n",
    "        should_save = False\n",
    "        async with write_lock:\n",
    "            results.append((idx, classified_dp))\n",
    "            completed += 1\n",
    "            full_datapoints[classify_to_full_pos[idx]] = classified_dp\n",
    "            total_prompt_tokens += p_tok\n",
    "            total_completion_tokens += c_tok\n",
    "            if passes > 0:\n",
    "                pass_count += 1\n",
    "            pbar.set_postfix(pass_rate=f\"{pass_count/completed:.2%}\", done=completed)\n",
    "            pbar.update(1)\n",
    "            should_save = completed % SAVE_EVERY == 0\n",
    "\n",
    "        if should_save:\n",
    "            async with save_lock:\n",
    "                save_count += 1\n",
    "                await anyio.to_thread.run_sync(\n",
    "                    _save_checkpoint, completed, total, save_count,\n",
    "                )\n",
    "\n",
    "    async with LLMPool(\n",
    "        base_url=API_BASE_URL,\n",
    "        api_key=API_KEY,\n",
    "        model=MODEL_NAME,\n",
    "        reasoning_effort=\"high\",\n",
    "        max_inflight=cfg.MAX_CONCURRENT_REQUESTS,\n",
    "        timeout=cfg.LLM_REQUEST_TIMEOUT_SECONDS,\n",
    "    ) as pool:\n",
    "        async with anyio.create_task_group() as tg:\n",
    "            tg.start_soon(config_reloader, pool)\n",
    "\n",
    "            async with anyio.create_task_group() as work_tg:\n",
    "                for idx, dp in enumerate(datapoints):\n",
    "                    await spawn_limit.acquire()\n",
    "                    async def _run(pool=pool, idx=idx, dp=dp):\n",
    "                        try:\n",
    "                            await process_one(pool, idx, dp)\n",
    "                        finally:\n",
    "                            spawn_limit.release()\n",
    "                    work_tg.start_soon(_run)\n",
    "\n",
    "            tg.cancel_scope.cancel()\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    # Final save\n",
    "    save_count += 1\n",
    "    _save_checkpoint(completed, total, save_count)\n",
    "\n",
    "    results.sort(key=lambda x: x[0])\n",
    "    classified = [dp for _, dp in results]\n",
    "    token_stats = {\n",
    "        \"prompt_tokens\": total_prompt_tokens,\n",
    "        \"completion_tokens\": total_completion_tokens,\n",
    "        \"total_tokens\": total_prompt_tokens + total_completion_tokens,\n",
    "    }\n",
    "    return classified, token_stats\n",
    "\n",
    "\n",
    "print(\"Classification engine ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: \n"
     ]
    }
   ],
   "source": [
    "async def test_api():\n",
    "    body = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are helpful.\"},\n",
    "            {\"role\": \"user\", \"content\": \"What is 2+2? Reply with just the number.\"}\n",
    "        ],\n",
    "        \"temperature\": 0.0,\n",
    "        \"max_tokens\": 32,\n",
    "    }\n",
    "    async with httpx.AsyncClient(timeout=httpx.Timeout(30, connect=5)) as client:\n",
    "        resp = await client.post(\n",
    "            f\"{API_BASE_URL}/chat/completions\",\n",
    "            json=body,\n",
    "            headers={\"Authorization\": f\"Bearer {API_KEY}\", \"Content-Type\": \"application/json\"},\n",
    "        )\n",
    "        if resp.status_code == 200:\n",
    "            data = resp.json()\n",
    "            print(f\"OK: {data['choices'][0]['message']['content']}\")\n",
    "        else:\n",
    "            print(f\"FAIL {resp.status_code}: {resp.text[:200]}\")\n",
    "\n",
    "await test_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying 16028 problems | level=8 | N_SAMPLES=1 | Model: gpt-oss-20b-high\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120734777aab4e9fb84498ad06810d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Classifying:   0%|          | 0/16028 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying llm_pool.LLMPool._post_with_retry.<locals>._do_post in 4.4613184717473855 seconds as it raised HTTPStatusError: Server error '502 Bad Gateway' for url 'http://127.0.0.1:8080/v1/chat/completions'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/502.\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mClassifying \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(to_classify)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m problems | level=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_LEVEL\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | N_SAMPLES=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN_SAMPLES\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_LABEL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m start_time = time.time()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m classified_datapoints, token_stats = \u001b[38;5;28;01mawait\u001b[39;00m run_classification(to_classify)\n\u001b[32m      5\u001b[39m elapsed = time.time() - start_time\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mDone in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00melapsed/\u001b[38;5;28mlen\u001b[39m(to_classify)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms/problem)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 139\u001b[39m, in \u001b[36mrun_classification\u001b[39m\u001b[34m(datapoints)\u001b[39m\n\u001b[32m    127\u001b[39m             \u001b[38;5;28;01mawait\u001b[39;00m anyio.to_thread.run_sync(\n\u001b[32m    128\u001b[39m                 _save_checkpoint, completed, total, save_count,\n\u001b[32m    129\u001b[39m             )\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m LLMPool(\n\u001b[32m    132\u001b[39m     base_url=API_BASE_URL,\n\u001b[32m    133\u001b[39m     api_key=API_KEY,\n\u001b[32m   (...)\u001b[39m\u001b[32m    137\u001b[39m     timeout=cfg.LLM_REQUEST_TIMEOUT_SECONDS,\n\u001b[32m    138\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m anyio.create_task_group() \u001b[38;5;28;01mas\u001b[39;00m tg:\n\u001b[32m    140\u001b[39m         tg.start_soon(config_reloader, pool)\n\u001b[32m    142\u001b[39m         \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m anyio.create_task_group() \u001b[38;5;28;01mas\u001b[39;00m work_tg:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIMO3_v2/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py:787\u001b[39m, in \u001b[36mTaskGroup.__aexit__\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    783\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m BaseExceptionGroup(\n\u001b[32m    784\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33munhandled errors in a TaskGroup\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._exceptions\n\u001b[32m    785\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m exc_val:\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exc_val\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cancel_scope.\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mtype\u001b[39m(exc), exc, exc.__traceback__):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 142\u001b[39m, in \u001b[36mrun_classification\u001b[39m\u001b[34m(datapoints)\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m anyio.create_task_group() \u001b[38;5;28;01mas\u001b[39;00m tg:\n\u001b[32m    140\u001b[39m     tg.start_soon(config_reloader, pool)\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m anyio.create_task_group() \u001b[38;5;28;01mas\u001b[39;00m work_tg:\n\u001b[32m    143\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m idx, dp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(datapoints):\n\u001b[32m    144\u001b[39m             \u001b[38;5;28;01mawait\u001b[39;00m spawn_limit.acquire()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIMO3_v2/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py:787\u001b[39m, in \u001b[36mTaskGroup.__aexit__\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    783\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m BaseExceptionGroup(\n\u001b[32m    784\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33munhandled errors in a TaskGroup\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._exceptions\n\u001b[32m    785\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m exc_val:\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exc_val\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cancel_scope.\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mtype\u001b[39m(exc), exc, exc.__traceback__):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 144\u001b[39m, in \u001b[36mrun_classification\u001b[39m\u001b[34m(datapoints)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m anyio.create_task_group() \u001b[38;5;28;01mas\u001b[39;00m work_tg:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m idx, dp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(datapoints):\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m spawn_limit.acquire()\n\u001b[32m    145\u001b[39m         \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run\u001b[39m(pool=pool, idx=idx, dp=dp):\n\u001b[32m    146\u001b[39m             \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AIMO3_v2/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py:1911\u001b[39m, in \u001b[36mSemaphore.acquire\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1909\u001b[39m \u001b[38;5;28mself\u001b[39m._waiters.append(fut)\n\u001b[32m   1910\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[32m   1912\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m CancelledError:\n\u001b[32m   1913\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(f\"Classifying {len(to_classify)} problems | level={MODEL_LEVEL} | N_SAMPLES={N_SAMPLES} | Model: {MODEL_LABEL}\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "classified_datapoints, token_stats = await run_classification(to_classify)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\nDone in {elapsed:.1f}s ({elapsed/len(to_classify):.2f}s/problem)\")\n",
    "print(f\"\\nToken usage:\")\n",
    "print(f\"  Prompt tokens:     {token_stats['prompt_tokens']:,}\")\n",
    "print(f\"  Completion tokens: {token_stats['completion_tokens']:,}\")\n",
    "print(f\"  Total tokens:      {token_stats['total_tokens']:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(classified_datapoints)\n",
    "\n",
    "def _current_level_passes(dp):\n",
    "    for entry in dp.get(AUDIT_FIELD_NAME, []):\n",
    "        if entry.get('level') == MODEL_LEVEL:\n",
    "            return entry.get('passes', 0)\n",
    "    return 0\n",
    "\n",
    "passed = sum(1 for dp in classified_datapoints if _current_level_passes(dp) > 0)\n",
    "failed = total - passed\n",
    "\n",
    "print(f\"Level {MODEL_LEVEL} ({MODEL_LABEL})\")\n",
    "print(f\"Total:  {total}\")\n",
    "print(f\"Passed: {passed} ({passed/total*100:.2f}%)\")\n",
    "print(f\"Failed: {failed} ({failed/total*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Classified Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge classified results back into the FULL dataset (preserves all original records)\n",
    "classified_set = {id(dp): cdp for dp, cdp in zip(to_classify, classified_datapoints)}\n",
    "\n",
    "final_datapoints = []\n",
    "for dp in full_datapoints:\n",
    "    if id(dp) in classified_set:\n",
    "        final_datapoints.append(classified_set[id(dp)])\n",
    "    else:\n",
    "        final_datapoints.append(dp)\n",
    "\n",
    "OUTPUT_DATASET_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(OUTPUT_DATASET_PATH, 'w', encoding='utf-8') as f:\n",
    "    for dp in final_datapoints:\n",
    "        f.write(json.dumps(dp, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(f\"Saved {len(final_datapoints)} records to {OUTPUT_DATASET_PATH}\")\n",
    "print(f\"  classified: {len(classified_datapoints)}, unchanged: {len(final_datapoints) - len(classified_datapoints)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
